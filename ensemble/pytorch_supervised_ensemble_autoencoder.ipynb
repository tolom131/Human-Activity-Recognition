{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "supervised ensemble autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "84bbda367bac7e7bffd9b7890a44d65326aaedad40e5a9021c2651157391b1ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3c12e7306ec40cd8fd3560636c7c6fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bb6c056e4dd4a4ea878fbe00c2237ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8501452472a04c91a8511cee50b7162a",
              "IPY_MODEL_f316b54817814226a572fc6304b62763",
              "IPY_MODEL_a3a6303abb65475096a15182d65f451e"
            ]
          }
        },
        "0bb6c056e4dd4a4ea878fbe00c2237ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8501452472a04c91a8511cee50b7162a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9788a9aa36484b97a1ad35b0e78db1a7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1826b1475fc842babd79c1eeb8150f1d"
          }
        },
        "f316b54817814226a572fc6304b62763": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f9661118d7b45b8b40ed4f62d776f72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1500,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 154,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9d3c1765e8f14edeaa5fa832e2536254"
          }
        },
        "a3a6303abb65475096a15182d65f451e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8728474ba71b40938e0675e5a1c60857",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 154/1500 [25:15&lt;3:40:46,  9.84s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db5f6876e7c04afd84141044e91b083a"
          }
        },
        "9788a9aa36484b97a1ad35b0e78db1a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1826b1475fc842babd79c1eeb8150f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f9661118d7b45b8b40ed4f62d776f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9d3c1765e8f14edeaa5fa832e2536254": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8728474ba71b40938e0675e5a1c60857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db5f6876e7c04afd84141044e91b083a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tolom131/Human-Activity-Recognition/blob/main/ensemble/pytorch_supervised_ensemble_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQGQXmOpA9J-"
      },
      "source": [
        "# Unsupervised image denoising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGBcGR2LA9KI"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNpI2DZ6A9KJ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage, Resize, Lambda, Normalize, Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from math import log10\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import math\n",
        "import torch as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20TiZsA_A9KO"
      },
      "source": [
        "## Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDynD4nA9KP"
      },
      "source": [
        "device        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ==================================================\n",
        "# determine optimal hyper-parameters to obtain best testing performance\n",
        "number_epoch    = 1500\n",
        "size_minibatch  = 128\n",
        "learning_rate   = 0.01\n",
        "alpha = 0.9\n",
        "warmup = 100\n",
        "# =================================================="
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FriR4w79i_Z",
        "outputId": "0bc95a9d-92d0-4808-a3c5-42283c254cac"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "directory_data  = './drive/MyDrive/HAR/'\n",
        "filename_data   = 'WISDM_at_v2.0_raw.txt'\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/HAR/')\n",
        "import wisdm_1_1\n",
        "import wisdm_2_0\n",
        "origianl_x, original_y, num_classes = wisdm_1_1.create_wisdm_1_1(directory_data + filename_data)\n",
        "#origianl_x, original_y, num_classes = wisdm_2_0.create_wisdm_2_0(directory_data + filename_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape :  (14423, 200, 3) y_train.shape:  (14423, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IsbQDqQ9mCD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(origianl_x, original_y, random_state=42, stratify=original_y, test_size=0.2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbHCZPpA9KR"
      },
      "source": [
        "## Costumize dataloader for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UveCjrBA9KS"
      },
      "source": [
        "class dataset (Dataset):\n",
        "    def  __init__(self, data, label):\n",
        "\n",
        "        self.data    = data\n",
        "        self.label    = label\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        data    = self.data[index]\n",
        "        label   = self.label[index]\n",
        "        return (data, label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357alwWgA9KU"
      },
      "source": [
        "## Construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7JDqjSVA9KU"
      },
      "source": [
        "## transformer를 통과하기 위해 데이터 shape 변경\n",
        "# x_train = x_train.reshape(-1, x_train.shape[2], x_train.shape[1])\n",
        "# x_test = x_test.reshape(-1, x_test.shape[2], x_test.shape[1])\n",
        "x_train = tf.FloatTensor(x_train)\n",
        "x_test = tf.FloatTensor(x_test)\n",
        "x_train = x_train.permute(0, 2, 1)\n",
        "x_test = x_test.permute(0, 2, 1)\n",
        "\n",
        "dataset_train = dataset(x_train, y_train) \n",
        "dataset_test  = dataset(x_test, y_test) \n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, num_workers=2)\n",
        "dataloader_test  = DataLoader(dataset_test,  batch_size=size_minibatch, shuffle=False, drop_last=True, num_workers=2) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yn9jMLrA9KX"
      },
      "source": [
        "## Class for the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htsiFor1QWwT"
      },
      "source": [
        "class Classifier(nn.Module):\n",
        "    def __init__(self, dim, channel, num_classes, is_alone=False):\n",
        "        super(Classifier, self).__init__()\n",
        "        \n",
        "        if is_alone:\n",
        "            self.dim = dim\n",
        "            self.channel = channel\n",
        "            self.num_classes = num_classes\n",
        "        else:\n",
        "            self.dim = dim\n",
        "            self.channel = channel\n",
        "            self.num_classes = num_classes\n",
        "\n",
        "        # original inputs shape : [batch_size, channel, dim]\n",
        "        # classifier inputs shape : [batch_size, channel*80, dim//8]\n",
        "\n",
        "        self.conv1 = nn.Conv1d(self.channel, 512, kernel_size=3, padding=1, stride=1)\n",
        "        self.batch1 = nn.BatchNorm1d(512)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv1d(512, 1024, kernel_size=3, padding=1, stride=1)\n",
        "        self.batch2 = nn.BatchNorm1d(1024)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        \n",
        "        self.lstm = nn.LSTM(25, 128, batch_first=True)\n",
        "        self.classifier = nn.Linear(128, self.num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.batch1(x)\n",
        "        #print(x.size())\n",
        "        x = self.relu1(x)\n",
        "        #print(x.size())\n",
        "        x = self.conv2(x)\n",
        "        #print(x.size())\n",
        "        x = self.batch2(x)\n",
        "        #print(x.size())\n",
        "        x = self.relu2(x)\n",
        "        #print(\"before LSTM : \", x.size())\n",
        "        x, _ = self.lstm(x)\n",
        "        #print(\"after LSTM : \", x.size())\n",
        "        x = x[:, -1, :]\n",
        "        #print(\"after -1 \" , x.size())\n",
        "        x = self.classifier(x)\n",
        "        #print(x.size())\n",
        "        return x  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe1o7K7dMbwi"
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SAE, self).__init__()\n",
        "\n",
        "        def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n",
        "            layers =  []\n",
        "            layers += [nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias)]\n",
        "            layers += [nn.BatchNorm1d(num_features=out_channels)]\n",
        "            layers += [nn.ReLU()]\n",
        "\n",
        "            cbr = nn.Sequential(*layers)\n",
        "\n",
        "            return cbr\n",
        "\n",
        "        # Contracting path\n",
        "        self.encoder_layers = [CBR2d(in_channels=3, out_channels=64), nn.MaxPool1d(kernel_size=2), CBR2d(in_channels=64, out_channels=128), \n",
        "                          nn.MaxPool1d(kernel_size=2), CBR2d(in_channels=128, out_channels=256), nn.MaxPool1d(kernel_size=2)]\n",
        "        self.encoder = nn.Sequential(*self.encoder_layers)\n",
        "\n",
        "        # Expansive path\n",
        "        self.decoder_layers = [CBR2d(in_channels=256, out_channels=128), nn.ConvTranspose1d(in_channels=128, out_channels=128, kernel_size=2, stride=2, padding=0, bias=True),\n",
        "                               CBR2d(in_channels=128, out_channels=64), nn.ConvTranspose1d(in_channels=64, out_channels=64, kernel_size=2, stride=2, padding=0, bias=True),\n",
        "                               CBR2d(in_channels=64,  out_channels=3), nn.ConvTranspose1d(in_channels=3, out_channels=3, kernel_size=2, stride=2, padding=0, bias=True)]\n",
        "        self.decoder = nn.Sequential(*self.decoder_layers)\n",
        "     \n",
        "    def forward(self, x):\n",
        "        \n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "\n",
        "        return encoded, decoded"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchsummary import summary as summary_\n",
        "# sae = SAE().to(device)\n",
        "# summary_(sae, (3, 200))"
      ],
      "metadata": {
        "id": "TSulRfCBNCM0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uig2PSDaTDu6"
      },
      "source": [
        "## model summary 용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8DSwKtMOqBH"
      },
      "source": [
        "## 모델링 과정을 위해 필요한 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA0KNRpEnnN6"
      },
      "source": [
        "def compute_mse_loss(input, prediction):\n",
        "    \n",
        "    mse = nn.MSELoss()\n",
        "    \n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    loss_mse = mse(prediction, input)\n",
        "    # ==================================================\n",
        "    \n",
        "    loss_mse_value = loss_mse.item() \n",
        "    \n",
        "    return loss_mse, loss_mse_value"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT9FgvXjcVBB"
      },
      "source": [
        "def compute_entropy_loss(inputs, prediction):\n",
        "    # inputs : label_train ,prediction : classified\n",
        "    inputs = torch.argmax(inputs, 1)\n",
        "    cross = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss_cross = cross(prediction, inputs)\n",
        "\n",
        "    loss_cross_value = loss_cross.item()\n",
        "    return loss_cross, loss_cross_value"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlSY2TrROn6W"
      },
      "source": [
        "def compute_accuracy(prediction, label):\n",
        "    # ================================================================================ \n",
        "    # complete the function body\n",
        "    b_Prediction = torch.argmax(prediction, 1)\n",
        "    b_label = torch.argmax(label, 1)\n",
        "    bCorrect = (b_Prediction == b_label)\n",
        "    accuracy = bCorrect.float().mean() * 100\n",
        "    # ================================================================================ \n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DYCbEtyPHW5"
      },
      "source": [
        "## 모델링 과정 정리를 위한 배열"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2GV2m67PGMD"
      },
      "source": [
        "total_loss_mean_train     = np.zeros(number_epoch)\n",
        "total_loss_std_train      = np.zeros(number_epoch)\n",
        "\n",
        "classified_loss_mean_train     = np.zeros(number_epoch)\n",
        "classified_loss_std_train      = np.zeros(number_epoch)\n",
        "\n",
        "decoded_loss_mean_train     = np.zeros(number_epoch)\n",
        "decoded_loss_std_train      = np.zeros(number_epoch)\n",
        "\n",
        "accuracy_mean_train = np.zeros(number_epoch)\n",
        "accuracy_std_train  = np.zeros(number_epoch)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss_mean_test     = np.zeros(number_epoch)\n",
        "total_loss_std_test      = np.zeros(number_epoch)\n",
        "\n",
        "classified_loss_mean_test     = np.zeros(number_epoch)\n",
        "classified_loss_std_test      = np.zeros(number_epoch)\n",
        "\n",
        "decoded_loss_mean_test    = np.zeros(number_epoch)\n",
        "decoded_loss_std_test      = np.zeros(number_epoch)\n",
        "\n",
        "accuracy_mean_test = np.zeros(number_epoch)\n",
        "accuracy_std_test  = np.zeros(number_epoch)"
      ],
      "metadata": {
        "id": "siA03vcV98ln"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTptbDGZA9KZ"
      },
      "source": [
        "## Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzsj97WB3_tq"
      },
      "source": [
        "autoencoder = SAE().to(device)\n",
        "classifier = Classifier(25, 256, 6).to(device)\n",
        "autoencoder_optimizer = torch.optim.Adam(autoencoder.parameters(), lr=learning_rate)\n",
        "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=learning_rate)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NKn_pSx3L0H"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3c12e7306ec40cd8fd3560636c7c6fa",
            "0bb6c056e4dd4a4ea878fbe00c2237ba",
            "8501452472a04c91a8511cee50b7162a",
            "f316b54817814226a572fc6304b62763",
            "a3a6303abb65475096a15182d65f451e",
            "9788a9aa36484b97a1ad35b0e78db1a7",
            "1826b1475fc842babd79c1eeb8150f1d",
            "1f9661118d7b45b8b40ed4f62d776f72",
            "9d3c1765e8f14edeaa5fa832e2536254",
            "8728474ba71b40938e0675e5a1c60857",
            "db5f6876e7c04afd84141044e91b083a"
          ]
        },
        "id": "UYEYvwqKmz-V",
        "outputId": "bc722b0d-1847-498e-f5ad-cc111a9cb90b"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    total_loss_train_epoch      = []\n",
        "    classified_loss_train_epoch = []\n",
        "    decoded_loss_train_epoch    = []\n",
        "    accuracy_train_epoch        = []\n",
        "\n",
        "    autoencoder.train()\n",
        "    classifier.train()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_train):\n",
        "\n",
        "        data_train = data.to(device)\n",
        "        label_train = label.to(device)\n",
        "        \n",
        "        encoded, decoded = autoencoder(data_train)\n",
        "        classified = classifier(encoded)\n",
        "\n",
        "        # classified loss\n",
        "        classified_loss, classfied_loss_value       = compute_entropy_loss(label_train, classified)\n",
        "\n",
        "        # decoded loss\n",
        "        decoded_loss, decoded_loss_value            = compute_mse_loss(data_train, decoded)\n",
        "\n",
        "        # classified accuracy\n",
        "        accuracy_train                              = compute_accuracy(classified, label_train).to(\"cpu\")\n",
        "        accuracy_train = accuracy_train.numpy()\n",
        "\n",
        "        if i >= 200:\n",
        "            total_loss = classified_loss + decoded_loss\n",
        "        else:\n",
        "            total_loss = classified_loss * (1-alpha) + decoded_loss * alpha\n",
        "\n",
        "        autoencoder_optimizer.zero_grad()\n",
        "        classifier_optimizer.zero_grad()\n",
        "        \n",
        "        total_loss.backward()\n",
        "\n",
        "        autoencoder_optimizer.step()\n",
        "        classifier_optimizer.step()\n",
        "\n",
        "        total_loss_train_epoch.append(total_loss.item())\n",
        "        classified_loss_train_epoch.append(classfied_loss_value)\n",
        "        decoded_loss_train_epoch.append(decoded_loss_value)\n",
        "        accuracy_train_epoch.append(accuracy_train)\n",
        "        \n",
        "    total_loss_mean_train[i]          = np.mean(total_loss_train_epoch)\n",
        "    total_loss_std_train[i]           = np.std(total_loss_train_epoch)\n",
        "\n",
        "    classified_loss_mean_train[i]     = np.mean(classified_loss_train_epoch)\n",
        "    classified_loss_std_train[i]      = np.std(classified_loss_train_epoch)\n",
        "\n",
        "    decoded_loss_mean_train[i]        = np.mean(decoded_loss_train_epoch)\n",
        "    decoded_loss_std_train[i]         = np.std(decoded_loss_train_epoch)\n",
        "\n",
        "    accuracy_mean_train[i]            = np.mean(accuracy_train_epoch)\n",
        "    accuracy_std_train[i]             = np.std(accuracy_train_epoch)\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    total_loss_test_epoch      = []\n",
        "    classified_loss_test_epoch = []\n",
        "    decoded_loss_test_epoch    = []\n",
        "    accuracy_test_epoch        = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        autoencoder.eval()\n",
        "        classifier.eval()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_test):\n",
        "\n",
        "        data_test = data.to(device)\n",
        "        label_test = label.to(device)\n",
        "        \n",
        "        encoded, decoded  = autoencoder(data_test)\n",
        "        classified        = classifier(encoded)\n",
        "\n",
        "        # classified loss\n",
        "        classified_loss, classfied_loss_value       = compute_entropy_loss(label_test, classified)\n",
        "\n",
        "        # decoded loss\n",
        "        decoded_loss, decoded_loss_value            = compute_mse_loss(data_test, decoded)\n",
        "\n",
        "        # classified accuracy\n",
        "        accuracy_test               = compute_accuracy(classified, label_test).to(\"cpu\")\n",
        "        accuracy_test = accuracy_test.numpy()\n",
        "\n",
        "        if i >= 200:\n",
        "            total_loss = classified_loss + decoded_loss\n",
        "        else:\n",
        "            total_loss = classified_loss * (1-alpha) + decoded_loss * alpha\n",
        "\n",
        "        total_loss_test_epoch.append(total_loss.item())\n",
        "        classified_loss_test_epoch.append(classfied_loss_value)\n",
        "        decoded_loss_test_epoch.append(decoded_loss_value)\n",
        "        accuracy_test_epoch.append(accuracy_test.item())\n",
        "\n",
        "    total_loss_mean_test[i]      = np.mean(total_loss_test_epoch)\n",
        "    total_loss_std_test[i]       = np.std(total_loss_test_epoch)\n",
        "\n",
        "    classified_loss_mean_test[i]      = np.mean(classified_loss_test_epoch)\n",
        "    classified_loss_std_test[i]       = np.std(classified_loss_test_epoch)\n",
        "\n",
        "    decoded_loss_mean_test[i]      = np.mean(decoded_loss_test_epoch)\n",
        "    decoded_loss_std_test[i]       = np.std(decoded_loss_test_epoch)\n",
        "\n",
        "    accuracy_mean_test[i]  = np.mean(accuracy_test_epoch)\n",
        "    accuracy_std_test[i]   = np.std(accuracy_test_epoch)\n",
        "\n",
        "    print(\"epoch : {}, train >> accuracy {:.8f}, total loss : {:.8f}, classified loss : {:.8f}, decoded loss : {:.8f}\".format(i, accuracy_mean_train[i], total_loss_mean_train[i], classified_loss_mean_train[i], decoded_loss_mean_train[i]))\n",
        "    print(\"epoch : {}, test  >> accuracy {:.8f}, total loss : {:.8f}, classified loss : {:.8f}, decoded loss : {:.8f}\".format(i, accuracy_mean_test[i], total_loss_mean_test[i], classified_loss_mean_test[i], decoded_loss_mean_test[i]))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3c12e7306ec40cd8fd3560636c7c6fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0, train >> accuracy 66.81423950, total loss : 0.15341722, classified loss : 0.91637917, decoded loss : 0.06864367\n",
            "epoch : 0, test  >> accuracy 73.79261364, total loss : 0.12392026, classified loss : 0.76347892, decoded loss : 0.05285819\n",
            "\n",
            "epoch : 1, train >> accuracy 74.79166412, total loss : 0.11839711, classified loss : 0.72128327, decoded loss : 0.05140976\n",
            "epoch : 1, test  >> accuracy 75.00000000, total loss : 0.11406131, classified loss : 0.71183174, decoded loss : 0.04764238\n",
            "\n",
            "epoch : 2, train >> accuracy 75.69444275, total loss : 0.11136302, classified loss : 0.70422449, decoded loss : 0.04548953\n",
            "epoch : 2, test  >> accuracy 75.95880682, total loss : 0.10195932, classified loss : 0.68486686, decoded loss : 0.03719181\n",
            "\n",
            "epoch : 3, train >> accuracy 76.48437500, total loss : 0.09860640, classified loss : 0.66096822, decoded loss : 0.03612175\n",
            "epoch : 3, test  >> accuracy 76.81107955, total loss : 0.09600729, classified loss : 0.64400509, decoded loss : 0.03511864\n",
            "\n",
            "epoch : 4, train >> accuracy 77.00521088, total loss : 0.09621056, classified loss : 0.64360026, decoded loss : 0.03538948\n",
            "epoch : 4, test  >> accuracy 73.15340909, total loss : 0.09428590, classified loss : 0.64128448, decoded loss : 0.03350828\n",
            "\n",
            "epoch : 5, train >> accuracy 78.56771088, total loss : 0.08934928, classified loss : 0.58975868, decoded loss : 0.03374824\n",
            "epoch : 5, test  >> accuracy 78.44460227, total loss : 0.08549515, classified loss : 0.56626144, decoded loss : 0.03207667\n",
            "\n",
            "epoch : 6, train >> accuracy 78.39409637, total loss : 0.08847447, classified loss : 0.58473729, decoded loss : 0.03333415\n",
            "epoch : 6, test  >> accuracy 76.24289773, total loss : 0.08573507, classified loss : 0.57595756, decoded loss : 0.03126590\n",
            "\n",
            "epoch : 7, train >> accuracy 78.76736450, total loss : 0.08533562, classified loss : 0.56195183, decoded loss : 0.03237827\n",
            "epoch : 7, test  >> accuracy 78.83522727, total loss : 0.08508812, classified loss : 0.56580341, decoded loss : 0.03167531\n",
            "\n",
            "epoch : 8, train >> accuracy 78.90625000, total loss : 0.08347921, classified loss : 0.55285340, decoded loss : 0.03132652\n",
            "epoch : 8, test  >> accuracy 78.72869318, total loss : 0.08149569, classified loss : 0.55806444, decoded loss : 0.02854361\n",
            "\n",
            "epoch : 9, train >> accuracy 78.98437500, total loss : 0.08121075, classified loss : 0.54143374, decoded loss : 0.03007486\n",
            "epoch : 9, test  >> accuracy 79.50994318, total loss : 0.08051293, classified loss : 0.55545479, decoded loss : 0.02774162\n",
            "\n",
            "epoch : 10, train >> accuracy 80.03472137, total loss : 0.07751251, classified loss : 0.51163159, decoded loss : 0.02927706\n",
            "epoch : 10, test  >> accuracy 80.68181818, total loss : 0.07434025, classified loss : 0.50580516, decoded loss : 0.02639971\n",
            "\n",
            "epoch : 11, train >> accuracy 80.67708588, total loss : 0.07451547, classified loss : 0.49196550, decoded loss : 0.02813213\n",
            "epoch : 11, test  >> accuracy 80.32670455, total loss : 0.07521291, classified loss : 0.51877821, decoded loss : 0.02592788\n",
            "\n",
            "epoch : 12, train >> accuracy 80.08680725, total loss : 0.07504777, classified loss : 0.50494758, decoded loss : 0.02728113\n",
            "epoch : 12, test  >> accuracy 80.29119318, total loss : 0.07449137, classified loss : 0.52370660, decoded loss : 0.02457856\n",
            "\n",
            "epoch : 13, train >> accuracy 80.09548950, total loss : 0.07257618, classified loss : 0.49521524, decoded loss : 0.02561628\n",
            "epoch : 13, test  >> accuracy 79.47443182, total loss : 0.07575963, classified loss : 0.54317606, decoded loss : 0.02382447\n",
            "\n",
            "epoch : 14, train >> accuracy 80.07812500, total loss : 0.07251047, classified loss : 0.50178887, decoded loss : 0.02481287\n",
            "epoch : 14, test  >> accuracy 80.11363636, total loss : 0.07167380, classified loss : 0.50663454, decoded loss : 0.02334483\n",
            "\n",
            "epoch : 15, train >> accuracy 80.33853912, total loss : 0.06830652, classified loss : 0.46633636, decoded loss : 0.02408098\n",
            "epoch : 15, test  >> accuracy 80.22017045, total loss : 0.07061825, classified loss : 0.50758801, decoded loss : 0.02206605\n",
            "\n",
            "epoch : 16, train >> accuracy 80.96353912, total loss : 0.06760758, classified loss : 0.46506802, decoded loss : 0.02344531\n",
            "epoch : 16, test  >> accuracy 81.03693182, total loss : 0.06646209, classified loss : 0.47385078, decoded loss : 0.02119669\n",
            "\n",
            "epoch : 17, train >> accuracy 81.29340363, total loss : 0.06566808, classified loss : 0.45162836, decoded loss : 0.02278361\n",
            "epoch : 17, test  >> accuracy 80.64630682, total loss : 0.06676430, classified loss : 0.46881653, decoded loss : 0.02209183\n",
            "\n",
            "epoch : 18, train >> accuracy 81.15451050, total loss : 0.06512683, classified loss : 0.45330190, decoded loss : 0.02199627\n",
            "epoch : 18, test  >> accuracy 81.60511364, total loss : 0.06478778, classified loss : 0.46289399, decoded loss : 0.02055376\n",
            "\n",
            "epoch : 19, train >> accuracy 80.97222137, total loss : 0.06662389, classified loss : 0.46648576, decoded loss : 0.02219480\n",
            "epoch : 19, test  >> accuracy 80.36221591, total loss : 0.06562332, classified loss : 0.47329095, decoded loss : 0.02032692\n",
            "\n",
            "epoch : 20, train >> accuracy 81.57118225, total loss : 0.06362290, classified loss : 0.44354981, decoded loss : 0.02140880\n",
            "epoch : 20, test  >> accuracy 81.85369318, total loss : 0.06386819, classified loss : 0.46314274, decoded loss : 0.01950435\n",
            "\n",
            "epoch : 21, train >> accuracy 81.70138550, total loss : 0.06273759, classified loss : 0.43894794, decoded loss : 0.02093644\n",
            "epoch : 21, test  >> accuracy 79.36789773, total loss : 0.06890609, classified loss : 0.50744155, decoded loss : 0.02017993\n",
            "\n",
            "epoch : 22, train >> accuracy 81.62326050, total loss : 0.06118664, classified loss : 0.42948505, decoded loss : 0.02026460\n",
            "epoch : 22, test  >> accuracy 81.78267045, total loss : 0.06102371, classified loss : 0.43869603, decoded loss : 0.01906012\n",
            "\n",
            "epoch : 23, train >> accuracy 81.47569275, total loss : 0.06267499, classified loss : 0.44446024, decoded loss : 0.02025440\n",
            "epoch : 23, test  >> accuracy 82.10227273, total loss : 0.06096649, classified loss : 0.43956628, decoded loss : 0.01889984\n",
            "\n",
            "epoch : 24, train >> accuracy 81.64930725, total loss : 0.06145604, classified loss : 0.43529578, decoded loss : 0.01991829\n",
            "epoch : 24, test  >> accuracy 76.13636364, total loss : 0.07996839, classified loss : 0.62616596, decoded loss : 0.01927977\n",
            "\n",
            "epoch : 25, train >> accuracy 79.07986450, total loss : 0.06832616, classified loss : 0.50139876, decoded loss : 0.02020698\n",
            "epoch : 25, test  >> accuracy 79.40340909, total loss : 0.06530656, classified loss : 0.48489833, decoded loss : 0.01868526\n",
            "\n",
            "epoch : 26, train >> accuracy 82.50000000, total loss : 0.05847044, classified loss : 0.41125851, decoded loss : 0.01927177\n",
            "epoch : 26, test  >> accuracy 80.07812500, total loss : 0.06281715, classified loss : 0.46665050, decoded loss : 0.01794677\n",
            "\n",
            "epoch : 27, train >> accuracy 82.19618225, total loss : 0.05925182, classified loss : 0.42237324, decoded loss : 0.01890499\n",
            "epoch : 27, test  >> accuracy 82.03125000, total loss : 0.05992906, classified loss : 0.43851136, decoded loss : 0.01786436\n",
            "\n",
            "epoch : 28, train >> accuracy 83.03819275, total loss : 0.05636086, classified loss : 0.39680840, decoded loss : 0.01853335\n",
            "epoch : 28, test  >> accuracy 82.45738636, total loss : 0.05735081, classified loss : 0.41456502, decoded loss : 0.01766034\n",
            "\n",
            "epoch : 29, train >> accuracy 82.93402863, total loss : 0.05705346, classified loss : 0.40356884, decoded loss : 0.01855175\n",
            "epoch : 29, test  >> accuracy 83.23863636, total loss : 0.05864568, classified loss : 0.42858175, decoded loss : 0.01754167\n",
            "\n",
            "epoch : 30, train >> accuracy 82.69965363, total loss : 0.05632552, classified loss : 0.39759165, decoded loss : 0.01840707\n",
            "epoch : 30, test  >> accuracy 82.81250000, total loss : 0.05653238, classified loss : 0.40971233, decoded loss : 0.01729017\n",
            "\n",
            "epoch : 31, train >> accuracy 82.71701050, total loss : 0.05655603, classified loss : 0.40315949, decoded loss : 0.01804453\n",
            "epoch : 31, test  >> accuracy 82.17329545, total loss : 0.05927877, classified loss : 0.43628169, decoded loss : 0.01738956\n",
            "\n",
            "epoch : 32, train >> accuracy 83.20312500, total loss : 0.05535724, classified loss : 0.39329841, decoded loss : 0.01780823\n",
            "epoch : 32, test  >> accuracy 81.39204545, total loss : 0.05802834, classified loss : 0.42566217, decoded loss : 0.01718014\n",
            "\n",
            "epoch : 33, train >> accuracy 83.16840363, total loss : 0.05585678, classified loss : 0.39734263, decoded loss : 0.01791391\n",
            "epoch : 33, test  >> accuracy 82.67045455, total loss : 0.05758123, classified loss : 0.41938598, decoded loss : 0.01738070\n",
            "\n",
            "epoch : 34, train >> accuracy 83.59375000, total loss : 0.05446615, classified loss : 0.38854707, decoded loss : 0.01734605\n",
            "epoch : 34, test  >> accuracy 83.16761364, total loss : 0.05557389, classified loss : 0.40917602, decoded loss : 0.01628477\n",
            "\n",
            "epoch : 35, train >> accuracy 84.15798950, total loss : 0.05286340, classified loss : 0.37241348, decoded loss : 0.01735783\n",
            "epoch : 35, test  >> accuracy 82.45738636, total loss : 0.05625562, classified loss : 0.41676925, decoded loss : 0.01619855\n",
            "\n",
            "epoch : 36, train >> accuracy 83.73263550, total loss : 0.05367516, classified loss : 0.38217273, decoded loss : 0.01717543\n",
            "epoch : 36, test  >> accuracy 83.34517045, total loss : 0.05534806, classified loss : 0.41046452, decoded loss : 0.01589068\n",
            "\n",
            "epoch : 37, train >> accuracy 83.97569275, total loss : 0.05267204, classified loss : 0.37429968, decoded loss : 0.01693564\n",
            "epoch : 37, test  >> accuracy 82.38636364, total loss : 0.05866037, classified loss : 0.44616026, decoded loss : 0.01560482\n",
            "\n",
            "epoch : 38, train >> accuracy 84.01909637, total loss : 0.05280432, classified loss : 0.37674477, decoded loss : 0.01681094\n",
            "epoch : 38, test  >> accuracy 83.84232955, total loss : 0.05476568, classified loss : 0.40807210, decoded loss : 0.01550941\n",
            "\n",
            "epoch : 39, train >> accuracy 84.07118225, total loss : 0.05165519, classified loss : 0.36741081, decoded loss : 0.01657123\n",
            "epoch : 39, test  >> accuracy 83.48721591, total loss : 0.05623656, classified loss : 0.41826134, decoded loss : 0.01601159\n",
            "\n",
            "epoch : 40, train >> accuracy 84.35763550, total loss : 0.05142659, classified loss : 0.36266269, decoded loss : 0.01684480\n",
            "epoch : 40, test  >> accuracy 82.06676136, total loss : 0.05609580, classified loss : 0.42093228, decoded loss : 0.01555841\n",
            "\n",
            "epoch : 41, train >> accuracy 83.79340363, total loss : 0.05281674, classified loss : 0.37681857, decoded loss : 0.01681653\n",
            "epoch : 41, test  >> accuracy 83.06107955, total loss : 0.05415748, classified loss : 0.40206873, decoded loss : 0.01550067\n",
            "\n",
            "epoch : 42, train >> accuracy 83.87152863, total loss : 0.05280355, classified loss : 0.37682612, decoded loss : 0.01680104\n",
            "epoch : 42, test  >> accuracy 82.52840909, total loss : 0.05692180, classified loss : 0.42638625, decoded loss : 0.01587019\n",
            "\n",
            "epoch : 43, train >> accuracy 84.01909637, total loss : 0.05175374, classified loss : 0.36906524, decoded loss : 0.01649690\n",
            "epoch : 43, test  >> accuracy 83.20312500, total loss : 0.05490267, classified loss : 0.41022542, decoded loss : 0.01542237\n",
            "\n",
            "epoch : 44, train >> accuracy 84.78298950, total loss : 0.04948024, classified loss : 0.34887996, decoded loss : 0.01621360\n",
            "epoch : 44, test  >> accuracy 83.91335227, total loss : 0.05278210, classified loss : 0.39441334, decoded loss : 0.01482308\n",
            "\n",
            "epoch : 45, train >> accuracy 85.32118225, total loss : 0.04825518, classified loss : 0.33563765, decoded loss : 0.01632380\n",
            "epoch : 45, test  >> accuracy 83.45170455, total loss : 0.05375787, classified loss : 0.40108778, decoded loss : 0.01516566\n",
            "\n",
            "epoch : 46, train >> accuracy 84.93055725, total loss : 0.04923528, classified loss : 0.34667124, decoded loss : 0.01618684\n",
            "epoch : 46, test  >> accuracy 82.95454545, total loss : 0.05570049, classified loss : 0.40958781, decoded loss : 0.01637968\n",
            "\n",
            "epoch : 47, train >> accuracy 84.84375000, total loss : 0.04953386, classified loss : 0.34722533, decoded loss : 0.01645703\n",
            "epoch : 47, test  >> accuracy 83.73579545, total loss : 0.05329677, classified loss : 0.39193005, decoded loss : 0.01567085\n",
            "\n",
            "epoch : 48, train >> accuracy 85.16493225, total loss : 0.04885946, classified loss : 0.34283907, decoded loss : 0.01619506\n",
            "epoch : 48, test  >> accuracy 84.05539773, total loss : 0.05257615, classified loss : 0.39234229, decoded loss : 0.01482436\n",
            "\n",
            "epoch : 49, train >> accuracy 85.36458588, total loss : 0.04798828, classified loss : 0.33597110, decoded loss : 0.01599018\n",
            "epoch : 49, test  >> accuracy 82.99005682, total loss : 0.05467650, classified loss : 0.41211192, decoded loss : 0.01496145\n",
            "\n",
            "epoch : 50, train >> accuracy 85.00868225, total loss : 0.04891761, classified loss : 0.34539248, decoded loss : 0.01597596\n",
            "epoch : 50, test  >> accuracy 82.70596591, total loss : 0.05625953, classified loss : 0.42373507, decoded loss : 0.01542891\n",
            "\n",
            "epoch : 51, train >> accuracy 84.21006775, total loss : 0.05019226, classified loss : 0.35642485, decoded loss : 0.01616642\n",
            "epoch : 51, test  >> accuracy 82.95454545, total loss : 0.05531424, classified loss : 0.41918998, decoded loss : 0.01488361\n",
            "\n",
            "epoch : 52, train >> accuracy 85.39062500, total loss : 0.04737763, classified loss : 0.33309813, decoded loss : 0.01563091\n",
            "epoch : 52, test  >> accuracy 83.70028409, total loss : 0.05436726, classified loss : 0.41156002, decoded loss : 0.01467917\n",
            "\n",
            "epoch : 53, train >> accuracy 85.35590363, total loss : 0.04711477, classified loss : 0.32985959, decoded loss : 0.01569868\n",
            "epoch : 53, test  >> accuracy 83.52272727, total loss : 0.05416984, classified loss : 0.41173978, decoded loss : 0.01443985\n",
            "\n",
            "epoch : 54, train >> accuracy 85.71180725, total loss : 0.04730497, classified loss : 0.33242206, decoded loss : 0.01562529\n",
            "epoch : 54, test  >> accuracy 83.84232955, total loss : 0.05343782, classified loss : 0.40372690, decoded loss : 0.01451680\n",
            "\n",
            "epoch : 55, train >> accuracy 85.41666412, total loss : 0.04693682, classified loss : 0.33022506, decoded loss : 0.01546035\n",
            "epoch : 55, test  >> accuracy 82.74147727, total loss : 0.05559786, classified loss : 0.41893587, decoded loss : 0.01522696\n",
            "\n",
            "epoch : 56, train >> accuracy 85.62500000, total loss : 0.04795314, classified loss : 0.33617459, decoded loss : 0.01592853\n",
            "epoch : 56, test  >> accuracy 83.94886364, total loss : 0.05167294, classified loss : 0.38707405, decoded loss : 0.01440615\n",
            "\n",
            "epoch : 57, train >> accuracy 86.05034637, total loss : 0.04517995, classified loss : 0.31350647, decoded loss : 0.01536589\n",
            "epoch : 57, test  >> accuracy 82.74147727, total loss : 0.05415827, classified loss : 0.41188439, decoded loss : 0.01441092\n",
            "\n",
            "epoch : 58, train >> accuracy 85.01736450, total loss : 0.04697223, classified loss : 0.33089416, decoded loss : 0.01542535\n",
            "epoch : 58, test  >> accuracy 83.62926136, total loss : 0.05449185, classified loss : 0.41664798, decoded loss : 0.01425227\n",
            "\n",
            "epoch : 59, train >> accuracy 85.39062500, total loss : 0.04757511, classified loss : 0.33733245, decoded loss : 0.01537985\n",
            "epoch : 59, test  >> accuracy 83.94886364, total loss : 0.05331437, classified loss : 0.40535558, decoded loss : 0.01419868\n",
            "\n",
            "epoch : 60, train >> accuracy 85.72916412, total loss : 0.04611201, classified loss : 0.32290171, decoded loss : 0.01535760\n",
            "epoch : 60, test  >> accuracy 83.70028409, total loss : 0.05596280, classified loss : 0.42485791, decoded loss : 0.01497446\n",
            "\n",
            "epoch : 61, train >> accuracy 85.83333588, total loss : 0.04689477, classified loss : 0.32960549, decoded loss : 0.01548247\n",
            "epoch : 61, test  >> accuracy 80.43323864, total loss : 0.06649562, classified loss : 0.53447999, decoded loss : 0.01449736\n",
            "\n",
            "epoch : 62, train >> accuracy 85.86805725, total loss : 0.04571386, classified loss : 0.31992205, decoded loss : 0.01524628\n",
            "epoch : 62, test  >> accuracy 84.16193182, total loss : 0.05306869, classified loss : 0.40465453, decoded loss : 0.01400360\n",
            "\n",
            "epoch : 63, train >> accuracy 85.96353912, total loss : 0.04558878, classified loss : 0.31744412, decoded loss : 0.01538263\n",
            "epoch : 63, test  >> accuracy 83.80681818, total loss : 0.05345599, classified loss : 0.40535810, decoded loss : 0.01435576\n",
            "\n",
            "epoch : 64, train >> accuracy 86.38888550, total loss : 0.04444944, classified loss : 0.30865457, decoded loss : 0.01509332\n",
            "epoch : 64, test  >> accuracy 83.27414773, total loss : 0.05555568, classified loss : 0.42562743, decoded loss : 0.01443659\n",
            "\n",
            "epoch : 65, train >> accuracy 85.88541412, total loss : 0.04561424, classified loss : 0.31798435, decoded loss : 0.01535090\n",
            "epoch : 65, test  >> accuracy 84.37500000, total loss : 0.05208113, classified loss : 0.38905265, decoded loss : 0.01463985\n",
            "\n",
            "epoch : 66, train >> accuracy 86.45833588, total loss : 0.04411355, classified loss : 0.30409390, decoded loss : 0.01522685\n",
            "epoch : 66, test  >> accuracy 83.73579545, total loss : 0.05267287, classified loss : 0.39942430, decoded loss : 0.01414494\n",
            "\n",
            "epoch : 67, train >> accuracy 86.41493225, total loss : 0.04391443, classified loss : 0.30234551, decoded loss : 0.01519987\n",
            "epoch : 67, test  >> accuracy 84.90767045, total loss : 0.05162003, classified loss : 0.39086465, decoded loss : 0.01392618\n",
            "\n",
            "epoch : 68, train >> accuracy 87.01388550, total loss : 0.04294079, classified loss : 0.29396749, decoded loss : 0.01504893\n",
            "epoch : 68, test  >> accuracy 82.56392045, total loss : 0.05733616, classified loss : 0.44196908, decoded loss : 0.01459916\n",
            "\n",
            "epoch : 69, train >> accuracy 85.52951050, total loss : 0.04596236, classified loss : 0.32107234, decoded loss : 0.01539458\n",
            "epoch : 69, test  >> accuracy 83.94886364, total loss : 0.05549698, classified loss : 0.42865827, decoded loss : 0.01403461\n",
            "\n",
            "epoch : 70, train >> accuracy 86.21527863, total loss : 0.04397026, classified loss : 0.30438752, decoded loss : 0.01503501\n",
            "epoch : 70, test  >> accuracy 84.23295455, total loss : 0.05365661, classified loss : 0.41013367, decoded loss : 0.01404805\n",
            "\n",
            "epoch : 71, train >> accuracy 86.86631775, total loss : 0.04281630, classified loss : 0.29259668, decoded loss : 0.01506293\n",
            "epoch : 71, test  >> accuracy 83.41619318, total loss : 0.05103448, classified loss : 0.38509946, decoded loss : 0.01391615\n",
            "\n",
            "epoch : 72, train >> accuracy 86.12847137, total loss : 0.04272150, classified loss : 0.29277051, decoded loss : 0.01493828\n",
            "epoch : 72, test  >> accuracy 84.97869318, total loss : 0.05007410, classified loss : 0.37834034, decoded loss : 0.01360007\n",
            "\n",
            "epoch : 73, train >> accuracy 86.19791412, total loss : 0.04356119, classified loss : 0.29962083, decoded loss : 0.01511012\n",
            "epoch : 73, test  >> accuracy 83.27414773, total loss : 0.05520640, classified loss : 0.42099753, decoded loss : 0.01456294\n",
            "\n",
            "epoch : 74, train >> accuracy 86.78819275, total loss : 0.04273713, classified loss : 0.29135259, decoded loss : 0.01511319\n",
            "epoch : 74, test  >> accuracy 83.52272727, total loss : 0.05622534, classified loss : 0.43040992, decoded loss : 0.01464928\n",
            "\n",
            "epoch : 75, train >> accuracy 86.91840363, total loss : 0.04305609, classified loss : 0.29693753, decoded loss : 0.01484705\n",
            "epoch : 75, test  >> accuracy 84.97869318, total loss : 0.05276746, classified loss : 0.40114431, decoded loss : 0.01405892\n",
            "\n",
            "epoch : 76, train >> accuracy 86.79687500, total loss : 0.04314246, classified loss : 0.29820033, decoded loss : 0.01480270\n",
            "epoch : 76, test  >> accuracy 83.27414773, total loss : 0.05694928, classified loss : 0.44187155, decoded loss : 0.01418014\n",
            "\n",
            "epoch : 77, train >> accuracy 86.80555725, total loss : 0.04331399, classified loss : 0.29882421, decoded loss : 0.01492397\n",
            "epoch : 77, test  >> accuracy 84.05539773, total loss : 0.05533802, classified loss : 0.42940510, decoded loss : 0.01377501\n",
            "\n",
            "epoch : 78, train >> accuracy 84.66146088, total loss : 0.04930687, classified loss : 0.35479183, decoded loss : 0.01536410\n",
            "epoch : 78, test  >> accuracy 84.12642045, total loss : 0.05434326, classified loss : 0.41580937, decoded loss : 0.01418036\n",
            "\n",
            "epoch : 79, train >> accuracy 86.49305725, total loss : 0.04378643, classified loss : 0.30299476, decoded loss : 0.01498551\n",
            "epoch : 79, test  >> accuracy 83.30965909, total loss : 0.05468080, classified loss : 0.42300401, decoded loss : 0.01375600\n",
            "\n",
            "epoch : 80, train >> accuracy 87.31771088, total loss : 0.04255243, classified loss : 0.29041533, decoded loss : 0.01501210\n",
            "epoch : 80, test  >> accuracy 84.44602273, total loss : 0.05377033, classified loss : 0.40903560, decoded loss : 0.01429641\n",
            "\n",
            "epoch : 81, train >> accuracy 87.00521088, total loss : 0.04266159, classified loss : 0.29161684, decoded loss : 0.01499990\n",
            "epoch : 81, test  >> accuracy 84.12642045, total loss : 0.05411105, classified loss : 0.41794142, decoded loss : 0.01368545\n",
            "\n",
            "epoch : 82, train >> accuracy 86.75347137, total loss : 0.04395054, classified loss : 0.30334278, decoded loss : 0.01512918\n",
            "epoch : 82, test  >> accuracy 83.94886364, total loss : 0.05422337, classified loss : 0.41738258, decoded loss : 0.01387235\n",
            "\n",
            "epoch : 83, train >> accuracy 86.84027863, total loss : 0.04219320, classified loss : 0.28953468, decoded loss : 0.01471081\n",
            "epoch : 83, test  >> accuracy 83.16761364, total loss : 0.05708133, classified loss : 0.44740757, decoded loss : 0.01371174\n",
            "\n",
            "epoch : 84, train >> accuracy 86.40625000, total loss : 0.04410824, classified loss : 0.30940100, decoded loss : 0.01463126\n",
            "epoch : 84, test  >> accuracy 83.62926136, total loss : 0.05366954, classified loss : 0.41369834, decoded loss : 0.01366634\n",
            "\n",
            "epoch : 85, train >> accuracy 87.08333588, total loss : 0.04275238, classified loss : 0.29374140, decoded loss : 0.01486471\n",
            "epoch : 85, test  >> accuracy 83.84232955, total loss : 0.05452829, classified loss : 0.42337306, decoded loss : 0.01354553\n",
            "\n",
            "epoch : 86, train >> accuracy 86.85763550, total loss : 0.04198594, classified loss : 0.28934984, decoded loss : 0.01450107\n",
            "epoch : 86, test  >> accuracy 83.70028409, total loss : 0.05390652, classified loss : 0.41444120, decoded loss : 0.01384710\n",
            "\n",
            "epoch : 87, train >> accuracy 87.17013550, total loss : 0.04138403, classified loss : 0.28105512, decoded loss : 0.01475391\n",
            "epoch : 87, test  >> accuracy 84.23295455, total loss : 0.05509954, classified loss : 0.42613445, decoded loss : 0.01387343\n",
            "\n",
            "epoch : 88, train >> accuracy 87.00521088, total loss : 0.04275848, classified loss : 0.29512268, decoded loss : 0.01471801\n",
            "epoch : 88, test  >> accuracy 83.84232955, total loss : 0.05361199, classified loss : 0.41328062, decoded loss : 0.01364881\n",
            "\n",
            "epoch : 89, train >> accuracy 86.90103912, total loss : 0.04190460, classified loss : 0.28612336, decoded loss : 0.01476918\n",
            "epoch : 89, test  >> accuracy 84.30397727, total loss : 0.05209941, classified loss : 0.39920405, decoded loss : 0.01353222\n",
            "\n",
            "epoch : 90, train >> accuracy 86.97916412, total loss : 0.04112351, classified loss : 0.28051502, decoded loss : 0.01452445\n",
            "epoch : 90, test  >> accuracy 83.87784091, total loss : 0.05381394, classified loss : 0.41752497, decoded loss : 0.01340161\n",
            "\n",
            "epoch : 91, train >> accuracy 86.92708588, total loss : 0.04265061, classified loss : 0.29344334, decoded loss : 0.01478475\n",
            "epoch : 91, test  >> accuracy 84.26846591, total loss : 0.05574561, classified loss : 0.42911640, decoded loss : 0.01425997\n",
            "\n",
            "epoch : 92, train >> accuracy 87.61284637, total loss : 0.04074690, classified loss : 0.27403083, decoded loss : 0.01482646\n",
            "epoch : 92, test  >> accuracy 84.26846591, total loss : 0.05405310, classified loss : 0.41820737, decoded loss : 0.01359152\n",
            "\n",
            "epoch : 93, train >> accuracy 87.42187500, total loss : 0.03976415, classified loss : 0.26601022, decoded loss : 0.01462570\n",
            "epoch : 93, test  >> accuracy 86.00852273, total loss : 0.05190133, classified loss : 0.39137506, decoded loss : 0.01418202\n",
            "\n",
            "epoch : 94, train >> accuracy 87.94271088, total loss : 0.03940447, classified loss : 0.26195837, decoded loss : 0.01467626\n",
            "epoch : 94, test  >> accuracy 84.69460227, total loss : 0.05180276, classified loss : 0.39609498, decoded loss : 0.01354807\n",
            "\n",
            "epoch : 95, train >> accuracy 87.08333588, total loss : 0.04474973, classified loss : 0.31352299, decoded loss : 0.01488604\n",
            "epoch : 95, test  >> accuracy 80.04261364, total loss : 0.06878496, classified loss : 0.55756653, decoded loss : 0.01447590\n",
            "\n",
            "epoch : 96, train >> accuracy 84.34027863, total loss : 0.04996668, classified loss : 0.36403250, decoded loss : 0.01507048\n",
            "epoch : 96, test  >> accuracy 82.91903409, total loss : 0.05644649, classified loss : 0.43998387, decoded loss : 0.01383123\n",
            "\n",
            "epoch : 97, train >> accuracy 85.93750000, total loss : 0.04489099, classified loss : 0.31599321, decoded loss : 0.01476852\n",
            "epoch : 97, test  >> accuracy 84.94318182, total loss : 0.05347575, classified loss : 0.41353481, decoded loss : 0.01346919\n",
            "\n",
            "epoch : 98, train >> accuracy 86.51041412, total loss : 0.04291282, classified loss : 0.29670022, decoded loss : 0.01471422\n",
            "epoch : 98, test  >> accuracy 82.95454545, total loss : 0.05525087, classified loss : 0.43120419, decoded loss : 0.01347828\n",
            "\n",
            "epoch : 99, train >> accuracy 86.72743225, total loss : 0.04229406, classified loss : 0.29154284, decoded loss : 0.01459976\n",
            "epoch : 99, test  >> accuracy 84.30397727, total loss : 0.05297141, classified loss : 0.40318403, decoded loss : 0.01405890\n",
            "\n",
            "epoch : 100, train >> accuracy 87.56944275, total loss : 0.03990505, classified loss : 0.26564084, decoded loss : 0.01482330\n",
            "epoch : 100, test  >> accuracy 84.73011364, total loss : 0.05244124, classified loss : 0.40258364, decoded loss : 0.01353653\n",
            "\n",
            "epoch : 101, train >> accuracy 87.92534637, total loss : 0.03970731, classified loss : 0.26728624, decoded loss : 0.01442076\n",
            "epoch : 101, test  >> accuracy 80.89488636, total loss : 0.05717907, classified loss : 0.45076030, decoded loss : 0.01344783\n",
            "\n",
            "epoch : 102, train >> accuracy 87.32638550, total loss : 0.04041386, classified loss : 0.27270970, decoded loss : 0.01460321\n",
            "epoch : 102, test  >> accuracy 84.51704545, total loss : 0.05327456, classified loss : 0.41199407, decoded loss : 0.01341683\n",
            "\n",
            "epoch : 103, train >> accuracy 87.47396088, total loss : 0.03969965, classified loss : 0.26566967, decoded loss : 0.01459187\n",
            "epoch : 103, test  >> accuracy 84.12642045, total loss : 0.05617947, classified loss : 0.44183374, decoded loss : 0.01332899\n",
            "\n",
            "epoch : 104, train >> accuracy 87.43923950, total loss : 0.04002771, classified loss : 0.27048424, decoded loss : 0.01442142\n",
            "epoch : 104, test  >> accuracy 83.70028409, total loss : 0.05482716, classified loss : 0.42475442, decoded loss : 0.01372413\n",
            "\n",
            "epoch : 105, train >> accuracy 88.40277863, total loss : 0.03778477, classified loss : 0.24839640, decoded loss : 0.01438347\n",
            "epoch : 105, test  >> accuracy 84.83664773, total loss : 0.05430252, classified loss : 0.42351504, decoded loss : 0.01327890\n",
            "\n",
            "epoch : 106, train >> accuracy 88.59375000, total loss : 0.03817857, classified loss : 0.25193815, decoded loss : 0.01442751\n",
            "epoch : 106, test  >> accuracy 81.56960227, total loss : 0.05751170, classified loss : 0.45436248, decoded loss : 0.01341716\n",
            "\n",
            "epoch : 107, train >> accuracy 87.88194275, total loss : 0.03887782, classified loss : 0.26023036, decoded loss : 0.01428309\n",
            "epoch : 107, test  >> accuracy 83.45170455, total loss : 0.06042963, classified loss : 0.48318193, decoded loss : 0.01345715\n",
            "\n",
            "epoch : 108, train >> accuracy 87.81250000, total loss : 0.04058667, classified loss : 0.27384131, decoded loss : 0.01466949\n",
            "epoch : 108, test  >> accuracy 84.05539773, total loss : 0.05970591, classified loss : 0.47339553, decoded loss : 0.01374039\n",
            "\n",
            "epoch : 109, train >> accuracy 87.28298950, total loss : 0.04300808, classified loss : 0.29994020, decoded loss : 0.01446007\n",
            "epoch : 109, test  >> accuracy 81.49857955, total loss : 0.05735368, classified loss : 0.45130129, decoded loss : 0.01358172\n",
            "\n",
            "epoch : 110, train >> accuracy 87.78646088, total loss : 0.04019735, classified loss : 0.26983491, decoded loss : 0.01468206\n",
            "epoch : 110, test  >> accuracy 84.44602273, total loss : 0.05422475, classified loss : 0.42152824, decoded loss : 0.01341326\n",
            "\n",
            "epoch : 111, train >> accuracy 89.60937500, total loss : 0.03738092, classified loss : 0.24409057, decoded loss : 0.01441318\n",
            "epoch : 111, test  >> accuracy 85.33380682, total loss : 0.05458964, classified loss : 0.42649299, decoded loss : 0.01326704\n",
            "\n",
            "epoch : 112, train >> accuracy 88.41146088, total loss : 0.03821441, classified loss : 0.25297925, decoded loss : 0.01435165\n",
            "epoch : 112, test  >> accuracy 85.01420455, total loss : 0.05403151, classified loss : 0.41849533, decoded loss : 0.01353553\n",
            "\n",
            "epoch : 113, train >> accuracy 87.05728912, total loss : 0.04160302, classified loss : 0.28548072, decoded loss : 0.01450549\n",
            "epoch : 113, test  >> accuracy 82.03125000, total loss : 0.06015895, classified loss : 0.47720646, decoded loss : 0.01382033\n",
            "\n",
            "epoch : 114, train >> accuracy 86.74478912, total loss : 0.04422000, classified loss : 0.30834082, decoded loss : 0.01487324\n",
            "epoch : 114, test  >> accuracy 84.87215909, total loss : 0.05246760, classified loss : 0.39999410, decoded loss : 0.01385354\n",
            "\n",
            "epoch : 115, train >> accuracy 87.24826050, total loss : 0.04106974, classified loss : 0.27826991, decoded loss : 0.01471417\n",
            "epoch : 115, test  >> accuracy 83.87784091, total loss : 0.05322235, classified loss : 0.40083408, decoded loss : 0.01459882\n",
            "\n",
            "epoch : 116, train >> accuracy 88.57638550, total loss : 0.03888109, classified loss : 0.25450279, decoded loss : 0.01492312\n",
            "epoch : 116, test  >> accuracy 84.65909091, total loss : 0.05346026, classified loss : 0.41034474, decoded loss : 0.01380643\n",
            "\n",
            "epoch : 117, train >> accuracy 88.48958588, total loss : 0.03934662, classified loss : 0.26204998, decoded loss : 0.01460180\n",
            "epoch : 117, test  >> accuracy 83.87784091, total loss : 0.05419043, classified loss : 0.41702044, decoded loss : 0.01387599\n",
            "\n",
            "epoch : 118, train >> accuracy 87.97743225, total loss : 0.03881651, classified loss : 0.25575927, decoded loss : 0.01471176\n",
            "epoch : 118, test  >> accuracy 86.18607955, total loss : 0.05254678, classified loss : 0.40623775, decoded loss : 0.01324778\n",
            "\n",
            "epoch : 119, train >> accuracy 88.37673950, total loss : 0.03792290, classified loss : 0.24893985, decoded loss : 0.01447657\n",
            "epoch : 119, test  >> accuracy 84.23295455, total loss : 0.05431786, classified loss : 0.42479789, decoded loss : 0.01315342\n",
            "\n",
            "epoch : 120, train >> accuracy 88.31597137, total loss : 0.03709197, classified loss : 0.24320661, decoded loss : 0.01419035\n",
            "epoch : 120, test  >> accuracy 85.75994318, total loss : 0.05408107, classified loss : 0.41811854, decoded loss : 0.01363246\n",
            "\n",
            "epoch : 121, train >> accuracy 89.03646088, total loss : 0.03664176, classified loss : 0.23449129, decoded loss : 0.01465848\n",
            "epoch : 121, test  >> accuracy 83.80681818, total loss : 0.05748733, classified loss : 0.44695889, decoded loss : 0.01421271\n",
            "\n",
            "epoch : 122, train >> accuracy 87.92534637, total loss : 0.03913833, classified loss : 0.26256293, decoded loss : 0.01431337\n",
            "epoch : 122, test  >> accuracy 84.44602273, total loss : 0.05501838, classified loss : 0.43017019, decoded loss : 0.01333485\n",
            "\n",
            "epoch : 123, train >> accuracy 87.89930725, total loss : 0.03925295, classified loss : 0.26235793, decoded loss : 0.01446351\n",
            "epoch : 123, test  >> accuracy 85.97301136, total loss : 0.05436906, classified loss : 0.42191608, decoded loss : 0.01353051\n",
            "\n",
            "epoch : 124, train >> accuracy 89.47048950, total loss : 0.03725228, classified loss : 0.24297513, decoded loss : 0.01439418\n",
            "epoch : 124, test  >> accuracy 84.62357955, total loss : 0.05623144, classified loss : 0.44365550, decoded loss : 0.01318432\n",
            "\n",
            "epoch : 125, train >> accuracy 89.11458588, total loss : 0.03781873, classified loss : 0.24744549, decoded loss : 0.01452687\n",
            "epoch : 125, test  >> accuracy 84.55255682, total loss : 0.05562942, classified loss : 0.43514735, decoded loss : 0.01346076\n",
            "\n",
            "epoch : 126, train >> accuracy 89.41840363, total loss : 0.03691439, classified loss : 0.23985537, decoded loss : 0.01436540\n",
            "epoch : 126, test  >> accuracy 85.26278409, total loss : 0.05374534, classified loss : 0.41835798, decoded loss : 0.01323282\n",
            "\n",
            "epoch : 127, train >> accuracy 88.77603912, total loss : 0.03705840, classified loss : 0.23999213, decoded loss : 0.01451020\n",
            "epoch : 127, test  >> accuracy 84.55255682, total loss : 0.05490057, classified loss : 0.43073989, decoded loss : 0.01314065\n",
            "\n",
            "epoch : 128, train >> accuracy 90.46006775, total loss : 0.03434011, classified loss : 0.21363559, decoded loss : 0.01441839\n",
            "epoch : 128, test  >> accuracy 85.72443182, total loss : 0.05505342, classified loss : 0.43181920, decoded loss : 0.01319056\n",
            "\n",
            "epoch : 129, train >> accuracy 88.83680725, total loss : 0.03740308, classified loss : 0.24492091, decoded loss : 0.01434554\n",
            "epoch : 129, test  >> accuracy 83.91335227, total loss : 0.05690893, classified loss : 0.44751960, decoded loss : 0.01350775\n",
            "\n",
            "epoch : 130, train >> accuracy 88.53298950, total loss : 0.03836735, classified loss : 0.25342319, decoded loss : 0.01447225\n",
            "epoch : 130, test  >> accuracy 83.06107955, total loss : 0.05912737, classified loss : 0.46920314, decoded loss : 0.01356340\n",
            "\n",
            "epoch : 131, train >> accuracy 89.68750000, total loss : 0.03620144, classified loss : 0.23392231, decoded loss : 0.01423245\n",
            "epoch : 131, test  >> accuracy 84.65909091, total loss : 0.05595102, classified loss : 0.43802552, decoded loss : 0.01349830\n",
            "\n",
            "epoch : 132, train >> accuracy 90.76388550, total loss : 0.03496547, classified loss : 0.22040484, decoded loss : 0.01436109\n",
            "epoch : 132, test  >> accuracy 86.93181818, total loss : 0.05357225, classified loss : 0.41496509, decoded loss : 0.01341749\n",
            "\n",
            "epoch : 133, train >> accuracy 91.16319275, total loss : 0.03427620, classified loss : 0.21500119, decoded loss : 0.01419565\n",
            "epoch : 133, test  >> accuracy 86.96732955, total loss : 0.05377996, classified loss : 0.41686073, decoded loss : 0.01343765\n",
            "\n",
            "epoch : 134, train >> accuracy 89.60069275, total loss : 0.03573214, classified loss : 0.22713490, decoded loss : 0.01446516\n",
            "epoch : 134, test  >> accuracy 86.39914773, total loss : 0.05441202, classified loss : 0.42419905, decoded loss : 0.01332457\n",
            "\n",
            "epoch : 135, train >> accuracy 88.54166412, total loss : 0.04086557, classified loss : 0.27664085, decoded loss : 0.01466831\n",
            "epoch : 135, test  >> accuracy 78.23153409, total loss : 0.07088601, classified loss : 0.57560324, decoded loss : 0.01480631\n",
            "\n",
            "epoch : 136, train >> accuracy 84.44444275, total loss : 0.05031186, classified loss : 0.36954687, decoded loss : 0.01484130\n",
            "epoch : 136, test  >> accuracy 82.13778409, total loss : 0.06277969, classified loss : 0.50503119, decoded loss : 0.01364064\n",
            "\n",
            "epoch : 137, train >> accuracy 87.36978912, total loss : 0.04188531, classified loss : 0.28811866, decoded loss : 0.01452605\n",
            "epoch : 137, test  >> accuracy 84.16193182, total loss : 0.05875031, classified loss : 0.46730537, decoded loss : 0.01335531\n",
            "\n",
            "epoch : 138, train >> accuracy 89.81771088, total loss : 0.03777242, classified loss : 0.24728842, decoded loss : 0.01449287\n",
            "epoch : 138, test  >> accuracy 87.46448864, total loss : 0.05302464, classified loss : 0.41154324, decoded loss : 0.01318924\n",
            "\n",
            "epoch : 139, train >> accuracy 89.40972137, total loss : 0.03658439, classified loss : 0.23534843, decoded loss : 0.01449950\n",
            "epoch : 139, test  >> accuracy 84.51704545, total loss : 0.05539918, classified loss : 0.43409093, decoded loss : 0.01332232\n",
            "\n",
            "epoch : 140, train >> accuracy 90.04340363, total loss : 0.03567044, classified loss : 0.22592862, decoded loss : 0.01453065\n",
            "epoch : 140, test  >> accuracy 84.62357955, total loss : 0.05574983, classified loss : 0.42838093, decoded loss : 0.01434637\n",
            "\n",
            "epoch : 141, train >> accuracy 90.28646088, total loss : 0.03449315, classified loss : 0.21730662, decoded loss : 0.01418054\n",
            "epoch : 141, test  >> accuracy 85.83096591, total loss : 0.05345295, classified loss : 0.41659608, decoded loss : 0.01310372\n",
            "\n",
            "epoch : 142, train >> accuracy 91.39756775, total loss : 0.03327403, classified loss : 0.20417351, decoded loss : 0.01428520\n",
            "epoch : 142, test  >> accuracy 86.68323864, total loss : 0.05374327, classified loss : 0.41523957, decoded loss : 0.01357701\n",
            "\n",
            "epoch : 143, train >> accuracy 90.94618225, total loss : 0.03356595, classified loss : 0.20874319, decoded loss : 0.01410182\n",
            "epoch : 143, test  >> accuracy 87.78409091, total loss : 0.05331262, classified loss : 0.40972162, decoded loss : 0.01371162\n",
            "\n",
            "epoch : 144, train >> accuracy 91.75347137, total loss : 0.03317490, classified loss : 0.20376172, decoded loss : 0.01422081\n",
            "epoch : 144, test  >> accuracy 85.22727273, total loss : 0.05895303, classified loss : 0.46569995, decoded loss : 0.01375893\n",
            "\n",
            "epoch : 145, train >> accuracy 92.09201050, total loss : 0.03258850, classified loss : 0.19802871, decoded loss : 0.01420626\n",
            "epoch : 145, test  >> accuracy 87.71306818, total loss : 0.05285154, classified loss : 0.41077818, decoded loss : 0.01308191\n",
            "\n",
            "epoch : 146, train >> accuracy 92.30034637, total loss : 0.03171254, classified loss : 0.18965285, decoded loss : 0.01416362\n",
            "epoch : 146, test  >> accuracy 86.93181818, total loss : 0.05681620, classified loss : 0.44540951, decoded loss : 0.01363916\n",
            "\n",
            "epoch : 147, train >> accuracy 91.84896088, total loss : 0.03321140, classified loss : 0.20428301, decoded loss : 0.01420345\n",
            "epoch : 147, test  >> accuracy 88.06818182, total loss : 0.05239027, classified loss : 0.40648767, decoded loss : 0.01304612\n",
            "\n",
            "epoch : 148, train >> accuracy 92.07465363, total loss : 0.03198082, classified loss : 0.19314846, decoded loss : 0.01407331\n",
            "epoch : 148, test  >> accuracy 86.39914773, total loss : 0.05668866, classified loss : 0.44750439, decoded loss : 0.01326469\n",
            "\n",
            "epoch : 149, train >> accuracy 92.28298950, total loss : 0.03193482, classified loss : 0.19082453, decoded loss : 0.01428041\n",
            "epoch : 149, test  >> accuracy 86.86079545, total loss : 0.05859581, classified loss : 0.46436607, decoded loss : 0.01351023\n",
            "\n",
            "epoch : 150, train >> accuracy 91.95312500, total loss : 0.03230041, classified loss : 0.19412183, decoded loss : 0.01432025\n",
            "epoch : 150, test  >> accuracy 87.28693182, total loss : 0.05782060, classified loss : 0.45835343, decoded loss : 0.01331696\n",
            "\n",
            "epoch : 151, train >> accuracy 92.52603912, total loss : 0.03139472, classified loss : 0.18528829, decoded loss : 0.01429543\n",
            "epoch : 151, test  >> accuracy 85.65340909, total loss : 0.05686233, classified loss : 0.44965920, decoded loss : 0.01321823\n",
            "\n",
            "epoch : 152, train >> accuracy 92.17013550, total loss : 0.03170719, classified loss : 0.19152003, decoded loss : 0.01395021\n",
            "epoch : 152, test  >> accuracy 87.39346591, total loss : 0.05753493, classified loss : 0.45680578, decoded loss : 0.01317151\n",
            "\n",
            "epoch : 153, train >> accuracy 90.81597137, total loss : 0.03639798, classified loss : 0.23603638, decoded loss : 0.01421593\n",
            "epoch : 153, test  >> accuracy 86.36363636, total loss : 0.06110937, classified loss : 0.48582029, decoded loss : 0.01391926\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "id": "51fM_Jv5bFsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchviz import make_dot\n",
        "make_dot(classified_loss, params=dict(classifier.named_parameters())).render(f\"graph\", format=\"png\")"
      ],
      "metadata": {
        "id": "kQ0M0CSYaUmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LULSrZv-UTDz"
      },
      "source": [
        "## Plot 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FdiEjDV0kb"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ENxj-BQUZ-7"
      },
      "source": [
        "print('[plot the training loss]')\n",
        "print('') \n",
        "plot_curve_error(total_loss_mean_train[:335], total_loss_std_train[:335], 'epoch', 'loss', 'loss (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bqK2U_jWXva"
      },
      "source": [
        "print('[plot the testing loss]')\n",
        "print('') \n",
        "plot_curve_error(total_loss_mean_test[:335], total_loss_std_test[:335], 'epoch', 'loss', 'loss (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J600wqOWgNF"
      },
      "source": [
        "print('[plot the traning accuracy]') \n",
        "print('') \n",
        "plot_curve_error(accuracy_mean_train[:335], accuracy_std_train[:335], 'epoch', 'accuracy', 'Accuracy (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsVmJXxnWIl9"
      },
      "source": [
        "print('[plot the testing accuracy]') \n",
        "print('') \n",
        "plot_curve_error(accuracy_mean_test[:335], accuracy_std_test[:335], 'epoch', 'accuracy', 'Accuracy (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8p8kkmUasj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}