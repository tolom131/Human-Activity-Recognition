{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment_08_solution_latest_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "84bbda367bac7e7bffd9b7890a44d65326aaedad40e5a9021c2651157391b1ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "562b4257117145c2a530cac5faaa46f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7430bd9e0aeb41ab9f59148be39d5d22",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4bc684ce8ed24c14a7d2a3e6e322a12a",
              "IPY_MODEL_853723b0f79e4193b4b9b90b9b84a068",
              "IPY_MODEL_77a0021194f34199882c9ed92b1d42ee"
            ]
          }
        },
        "7430bd9e0aeb41ab9f59148be39d5d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4bc684ce8ed24c14a7d2a3e6e322a12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7142a7c190db4c1f96b0e2f3e2d23376",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5098804cc2d34c9595643449c2d516ca"
          }
        },
        "853723b0f79e4193b4b9b90b9b84a068": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e00d08fdb97e4552b1c6dd0edd03ffa9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 50,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08ec1d58cf9444a68cbe389e92273bd6"
          }
        },
        "77a0021194f34199882c9ed92b1d42ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_abb4d74924fc4d2faccb3ded4e356f64",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 50/50 [04:57&lt;00:00,  5.91s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83091fbacc85451eb5a1580c03ef2493"
          }
        },
        "7142a7c190db4c1f96b0e2f3e2d23376": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5098804cc2d34c9595643449c2d516ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e00d08fdb97e4552b1c6dd0edd03ffa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08ec1d58cf9444a68cbe389e92273bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abb4d74924fc4d2faccb3ded4e356f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83091fbacc85451eb5a1580c03ef2493": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQGQXmOpA9J-"
      },
      "source": [
        "# Unsupervised image denoising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGBcGR2LA9KI"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNpI2DZ6A9KJ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage, Resize, Lambda, Normalize, Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from math import log10\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import math\n",
        "import torch as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20TiZsA_A9KO"
      },
      "source": [
        "## Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDynD4nA9KP"
      },
      "source": [
        "device        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ==================================================\n",
        "# determine optimal hyper-parameters to obtain best testing performance\n",
        "number_epoch    = 50\n",
        "size_minibatch  = 64\n",
        "learning_rate   = 0.1\n",
        "# =================================================="
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FriR4w79i_Z",
        "outputId": "c7201971-7a6c-47c6-b77a-fc235d9d441d"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "directory_data  = './drive/MyDrive/HAR/'\n",
        "filename_data   = 'WISDM_at_v2.0_raw.txt'\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/HAR/')\n",
        "import wisdm_1_1\n",
        "import wisdm_2_0\n",
        "# x_train, y_train, num_classes = wisdm_1_1.create_wisdm_1_1(directory_data + filename_data)\n",
        "origianl_x, original_y, num_classes = wisdm_2_0.create_wisdm_2_0(directory_data + filename_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape :  (14423, 200, 3) y_train.shape:  (14423, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IsbQDqQ9mCD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(origianl_x, original_y, random_state=42, stratify=original_y, test_size=0.2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbHCZPpA9KR"
      },
      "source": [
        "## Costumize dataloader for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UveCjrBA9KS"
      },
      "source": [
        "class dataset (Dataset):\n",
        "    def  __init__(self, data, label):\n",
        "\n",
        "        self.data    = data\n",
        "        self.label    = label\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        data    = self.data[index]\n",
        "        label   = self.label[index]\n",
        "        return (data, label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357alwWgA9KU"
      },
      "source": [
        "## Construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7JDqjSVA9KU"
      },
      "source": [
        "## transformer를 통과하기 위해 데이터 shape 변경\n",
        "x_train = x_train.reshape(-1, x_train.shape[2], x_train.shape[1])\n",
        "x_test = x_test.reshape(-1, x_test.shape[2], x_test.shape[1])\n",
        "\n",
        "dataset_train = dataset(x_train, y_train) \n",
        "dataset_test  = dataset(x_test, y_test) \n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, num_workers=2)\n",
        "dataloader_test  = DataLoader(dataset_test,  batch_size=size_minibatch, shuffle=False, drop_last=True, num_workers=2) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yn9jMLrA9KX"
      },
      "source": [
        "## Class for the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHuu2uZ9SyRm"
      },
      "source": [
        "class my_MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size=200, num_heads=1):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.multihead = nn.MultiheadAttention(emb_size, num_heads, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # split keys, queries and values in num_heads\n",
        "        x = self.multihead(inputs, inputs, inputs, need_weights=False)\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TCHYzLmjd3I"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \n",
        "    def __init__(self,max_len,d_model,device):\n",
        "        super(PositionalEncoding,self).__init__()\n",
        "        \n",
        "        self.encoding = torch.zeros(max_len,d_model,device = device)\n",
        "        self.encoding.requires_grad = False # we don't need to compute gradient\n",
        "        \n",
        "        pos = torch.arange(0,max_len,device=device)\n",
        "        pos = pos.float().unsqueeze(dim = 1)\n",
        "        \n",
        "        _2i = torch.arange(0,d_model,step = 2,device = device).float()\n",
        "        \n",
        "        self.encoding[:,0::2] = torch.sin(pos/(10000**(_2i/d_model)))\n",
        "        self.encoding[:,1::2] = torch.cos(pos/(10000**(_2i/d_model)))\n",
        "        \n",
        "    def forward(self,x):\n",
        "        batch_size,seq_len = x.size()\n",
        "        \n",
        "        return self.encoding[:seq_len,:]\n",
        "\n",
        "class ScaleDotProductAttention(nn.Module):\n",
        "    '''\n",
        "    Compute scale dot product attention\n",
        "    실질적인 attention score을 계산하는 클래스\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(ScaleDotProductAttention,self).__init__()\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self,q,k,v,mask = None, e = 1e-12):\n",
        "        # input is 4 dimension tensor\n",
        "        # [batch_size,head,length,d_tensor]\n",
        "        batch_size,head,length,d_tensor = k.size()\n",
        "        \n",
        "        # 1. dot product Query with Key^T to compute similarity\n",
        "        k_t = k.view(batch_size,head,d_tensor,length)\n",
        "        score = (q @ k_t) / math.sqrt(d_tensor) # @연산은 np.matmul과 같은 역할\n",
        "        \n",
        "        '''\n",
        "        Note) '@' operator\n",
        "        If either argument is N-D, N > 2, \n",
        "        it is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.\n",
        "        '''\n",
        "        \n",
        "        # 2. applying masking(optional)\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask == 0 ,-e)\n",
        "        \n",
        "        # 3. pass tem softmax to make [0,1] range\n",
        "        score = self.softmax(score)\n",
        "        \n",
        "        # 4. Multiply with Value\n",
        "        v = score @ v\n",
        "        \n",
        "        return v, score\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \n",
        "    def __init__(self,d_model,n_head):\n",
        "        super(MultiHeadAttention,self).__init__()\n",
        "        self.n_head = n_head\n",
        "        self.attention = ScaleDotProductAttention()\n",
        "        self.w_q = nn.Linear(d_model,d_model)\n",
        "        self.w_k = nn.Linear(d_model,d_model)\n",
        "        self.w_v = nn.Linear(d_model,d_model)\n",
        "        self.w_concat = nn.Linear(d_model,d_model)\n",
        "    \n",
        "    def split(self,tensor):\n",
        "        '''\n",
        "        splits tensor by number of head\n",
        "        \n",
        "        param tensor = [batch_size,length,d_model]\n",
        "        out = [batch_size,head,length,d_tensor]\n",
        "        \n",
        "        d_model을 head와 d_tensor로 쪼개는걸로 이해하면 될듯. \n",
        "        d_tensor는 head의 값에 따라 변함.(head값은 정해주는 값이기 때문..)\n",
        "        '''\n",
        "        batch_size,length,d_model = tensor.size()\n",
        "        \n",
        "        d_tensor = d_model//self.n_head\n",
        "        \n",
        "        tensor = tensor.view(batch_size,self.n_head,length,d_tensor)\n",
        "        \n",
        "        return tensor\n",
        "    \n",
        "    def concat(self,tensor):\n",
        "        '''\n",
        "        inverse function of self.split(tensor = torch.Tensor)\n",
        "        \n",
        "        param tensor = [batch_size,head,length,d_tensor]\n",
        "        out = [batch_size,length,d_model]\n",
        "        '''\n",
        "        batch_size,head,length,d_tensor = tensor.size()\n",
        "        d_model = head*d_tensor\n",
        "        \n",
        "        tensor = tensor.view(batch_size,length,d_model)\n",
        "        return tensor\n",
        "    \n",
        "    def forward(self,q,k,v,mask = None):\n",
        "        \n",
        "        #1. dot product with weight metrics\n",
        "        q,k,v = self.w_q(q),self.w_k(k),self.w_v(v)\n",
        "        \n",
        "        # 2. split tensor by number of heads\n",
        "        q,k,v = self.split(q),self.split(k),self.split(v)\n",
        "        \n",
        "        # 3. do scale dot product to compute similarity (attention 계산)\n",
        "        out,attention = self.attention(q,k,v, mask = mask)\n",
        "        \n",
        "        # 4. concat and pass to linear layer\n",
        "        out = self.concat(out)\n",
        "        out = self.w_concat(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QGenrzTEAR"
      },
      "source": [
        "# 수정: 오토 인코더의 인코더처럼 만들기 위해 마지막 Linear에서 그 크기를 줄여준다.\n",
        "class FeedForwardBlock_Encoder(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, reduction=1):\n",
        "        super(FeedForwardBlock_Encoder, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channel, in_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.batch1 = nn.BatchNorm1d(in_channel)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channel, out_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.batch2 = nn.BatchNorm1d(out_channel)            \n",
        "\n",
        "        self.pool = nn.MaxPool1d(2, 2)\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.relu1(x)\n",
        "        x = self.batch1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.batch2(x)\n",
        "\n",
        "        if self.reduction == 2:\n",
        "            x = self.pool(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2fieNGYV4xe"
      },
      "source": [
        "# Now create the Transformer Encoder Block\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, dim=768, in_channel=16, out_channel=16, reduction=1, **kwargs):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "\n",
        "        self.laynorm1 = nn.LayerNorm(dim)\n",
        "        self.multihead1 = MultiHeadAttention(dim, 1)\n",
        "\n",
        "        self.laynorm2 = nn.LayerNorm(dim)\n",
        "        self.ff = FeedForwardBlock_Encoder(in_channel, out_channel, reduction=reduction)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        _x = inputs\n",
        "        x = self.laynorm1(inputs)\n",
        "        x = self.multihead1(x, x, x)\n",
        "        x += _x\n",
        "\n",
        "        x = self.laynorm2(x)\n",
        "        x = self.ff(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26QaLC6AWsO9"
      },
      "source": [
        "# 수정: 오토 인코더의 인코더처럼 만들기 위해 마지막 Linear에서 그 크기를 줄여준다.\n",
        "class FeedForwardBlock_Decoder(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, amp=1):\n",
        "        super(FeedForwardBlock_Decoder, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channel, in_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.batch1 = nn.BatchNorm1d(in_channel)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channel, out_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.batch2 = nn.BatchNorm1d(out_channel)            \n",
        "\n",
        "        self.pool = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
        "        self.amp = amp\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.relu1(x)\n",
        "        x = self.batch1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.batch2(x)\n",
        "\n",
        "        if self.amp == 2:\n",
        "            x = self.pool(x)\n",
        "        return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ys44YMV2bL"
      },
      "source": [
        "# Now create the Transformer Encoder Block\n",
        "class TransformerDecoderBlock(nn.Module):\n",
        "    def __init__(self, dim=768, in_channel=16, out_channel=16, amp=1, **kwargs):\n",
        "        super(TransformerDecoderBlock, self).__init__()\n",
        "\n",
        "        self.laynorm1 = nn.LayerNorm(dim)\n",
        "        self.multihead1 = MultiHeadAttention(dim, 1)\n",
        "\n",
        "        self.laynorm2 = nn.LayerNorm(dim)\n",
        "        self.ff =  FeedForwardBlock_Decoder(in_channel, out_channel, amp)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        _x = inputs\n",
        "        x = self.laynorm1(inputs)\n",
        "        x = self.multihead1(x, x, x)\n",
        "        x += _x\n",
        "\n",
        "        x = self.laynorm2(x)\n",
        "        x = self.ff(x)\n",
        "        return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VPt0SXOTuS3"
      },
      "source": [
        "class Conseuctive_Conv(nn.Sequential):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__(\n",
        "            nn.Conv1d(dim, dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(dim, dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(dim, dim, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dim, channel):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.channel = channel\n",
        "\n",
        "        self.conv1 = Conseuctive_Conv(channel*20)\n",
        "        self.conv2 = Conseuctive_Conv(channel*40)\n",
        "\n",
        "        self.encoder12 = TransformerEncoderBlock(dim=dim,     in_channel=channel,   out_channel=channel*20,  reduction=2, **kwargs)\n",
        "        self.encoder22 = TransformerEncoderBlock(dim=dim//2,  in_channel=channel*20, out_channel=channel*40,  reduction=2, **kwargs)\n",
        "        self.encoder32 = TransformerEncoderBlock(dim=dim//4,  in_channel=channel*40, out_channel=channel*80,  reduction=2, **kwargs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.encoder12(inputs)    \n",
        "        x = self.conv1(x)\n",
        "        x = self.encoder22(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.encoder32(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dim, channel):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.channel = channel\n",
        "\n",
        "        self.conv3 = Conseuctive_Conv(channel*40)\n",
        "        self.conv4 = Conseuctive_Conv(channel*20)\n",
        "\n",
        "        self.decoder12 = TransformerDecoderBlock(dim=dim//8,  in_channel=channel*80, out_channel=channel*40, amp=2, **kwargs)\n",
        "        self.decoder22 = TransformerDecoderBlock(dim=dim//4,  in_channel=channel*40, out_channel=channel*20, amp=2, **kwargs)\n",
        "        self.decoder32 = TransformerDecoderBlock(dim=dim//2,  in_channel=channel*20, out_channel=channel,   amp=2, **kwargs)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.decoder12(inputs)\n",
        "        x = self.conv3(x)\n",
        "        x = self.decoder22(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.decoder32(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class Transformer_Autoencoder(nn.Module):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Transformer_Autoencoder, self).__init__()\n",
        "\n",
        "        dim = 200\n",
        "        channel = 3\n",
        "\n",
        "        self.conv1 = Conseuctive_Conv(channel*20)\n",
        "        self.conv2 = Conseuctive_Conv(channel*40)\n",
        "\n",
        "        self.conv3 = Conseuctive_Conv(channel*40)\n",
        "        self.conv4 = Conseuctive_Conv(channel*20)\n",
        "\n",
        "        self.encoder12 = TransformerEncoderBlock(dim=dim,     in_channel=channel,   out_channel=channel*20,  reduction=2, **kwargs)\n",
        "        self.encoder22 = TransformerEncoderBlock(dim=dim//2,  in_channel=channel*20, out_channel=channel*40,  reduction=2, **kwargs)\n",
        "        self.encoder32 = TransformerEncoderBlock(dim=dim//4,  in_channel=channel*40, out_channel=channel*80,  reduction=2, **kwargs)\n",
        "\n",
        "        self.decoder12 = TransformerDecoderBlock(dim=dim//8,  in_channel=channel*80, out_channel=channel*40, amp=2, **kwargs)\n",
        "        self.decoder22 = TransformerDecoderBlock(dim=dim//4,  in_channel=channel*40, out_channel=channel*20, amp=2, **kwargs)\n",
        "        self.decoder32 = TransformerDecoderBlock(dim=dim//2,  in_channel=channel*20, out_channel=channel,   amp=2, **kwargs)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.encoder12(inputs)    \n",
        "        x = self.conv1(x)\n",
        "        x = self.encoder22(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.encoder32(x)\n",
        "\n",
        "        x = self.decoder12(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.decoder22(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.decoder32(x)\n",
        "\n",
        "        return x\n",
        "        "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFPWFJrfTrU9"
      },
      "source": [
        "class Supervied_Autoencoder(nn.Module):\n",
        "    def __init__(self, dim, channel):\n",
        "        super(Supervied_Autoencoder, self).__init__()\n",
        "        \n",
        "        self.dim = dim\n",
        "        self.channel = channel\n",
        "\n",
        "        self.encoder = Encoder(dim, channel)\n",
        "        self.decoder = Decoder(dim, channel)\n",
        "\n",
        "        self. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mOHlncuCTPuw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uig2PSDaTDu6"
      },
      "source": [
        "## model summary 용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmCOhVRTAUly"
      },
      "source": [
        "# from torchsummary import summary as summary_\n",
        "\n",
        "# model = Transformer_Autoencoder().to(device)\n",
        "# summary_(model, (3, 200))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8DSwKtMOqBH"
      },
      "source": [
        "## 모델링 과정을 위해 필요한 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCOI_G1tnmUE"
      },
      "source": [
        "def compute_prediction(model, input):\n",
        "    prediction = model(input)\n",
        "    return prediction"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA0KNRpEnnN6"
      },
      "source": [
        "def compute_loss(input, prediction):\n",
        "    \n",
        "    mse = nn.MSELoss()\n",
        "    \n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    loss_mse = mse(prediction, input)\n",
        "    # ==================================================\n",
        "    \n",
        "    loss_mse_value = loss_mse.item() \n",
        "    \n",
        "    return loss_mse, loss_mse_value"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlSY2TrROn6W"
      },
      "source": [
        "def compute_accuracy(prediction, label):\n",
        "    # ================================================================================ \n",
        "    # complete the function body\n",
        "    b_Prediction = torch.argmax(prediction, 1)\n",
        "    bCorrect = (b_Prediction == label)\n",
        "    accuracy = bCorrect.float().mean() * 100\n",
        "    # ================================================================================ \n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DYCbEtyPHW5"
      },
      "source": [
        "## 모델링 과정 정리를 위한 배열"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2GV2m67PGMD"
      },
      "source": [
        "loss_mean_train     = np.zeros(number_epoch)\n",
        "loss_std_train      = np.zeros(number_epoch)\n",
        "accuracy_mean_train = np.zeros(number_epoch)\n",
        "accuracy_std_train  = np.zeros(number_epoch)\n",
        "\n",
        "loss_mean_test      = np.zeros(number_epoch)\n",
        "loss_std_test       = np.zeros(number_epoch)\n",
        "accuracy_mean_test  = np.zeros(number_epoch)\n",
        "accuracy_std_test   = np.zeros(number_epoch)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTptbDGZA9KZ"
      },
      "source": [
        "## Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MgUbMJdA9KZ"
      },
      "source": [
        "model = Transformer_Autoencoder().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "562b4257117145c2a530cac5faaa46f8",
            "7430bd9e0aeb41ab9f59148be39d5d22",
            "4bc684ce8ed24c14a7d2a3e6e322a12a",
            "853723b0f79e4193b4b9b90b9b84a068",
            "77a0021194f34199882c9ed92b1d42ee",
            "7142a7c190db4c1f96b0e2f3e2d23376",
            "5098804cc2d34c9595643449c2d516ca",
            "e00d08fdb97e4552b1c6dd0edd03ffa9",
            "08ec1d58cf9444a68cbe389e92273bd6",
            "abb4d74924fc4d2faccb3ded4e356f64",
            "83091fbacc85451eb5a1580c03ef2493"
          ]
        },
        "id": "UYEYvwqKmz-V",
        "outputId": "c7d8acb7-2736-48ea-e1ca-51832b3f9a73"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_train_epoch        = []\n",
        "    accuracy_train_epoch    = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_train):\n",
        "\n",
        "        data_train = data.to(device)\n",
        "        label_train = label.to(device)\n",
        "        \n",
        "        prediction_train                = compute_prediction(model, data_train)\n",
        "        loss_train, loss_value_train    = compute_loss(prediction_train, data_train)\n",
        "        # accuracy_train                  = compute_accuracy(prediction_train, data_train).to(\"cpu\")\n",
        "        # accuracy_train = accuracy_train.numpy()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_train_epoch.append(loss_value_train)\n",
        "        # accuracy_train_epoch.append(accuracy_train)\n",
        "\n",
        "    loss_mean_train[i]      = np.mean(loss_train_epoch)\n",
        "    loss_std_train[i]       = np.std(loss_train_epoch)\n",
        "\n",
        "    # accuracy_mean_train[i]  = np.mean(accuracy_train_epoch)\n",
        "    # accuracy_std_train[i]   = np.std(accuracy_train_epoch)\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_test_epoch        = []\n",
        "    accuracy_test_epoch    = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_test):\n",
        "\n",
        "        data_test = data.to(device)\n",
        "        label_test = label.to(device)\n",
        "        \n",
        "        prediction_test             = compute_prediction(model, data_test)\n",
        "        loss_test, loss_value_test  = compute_loss(prediction_test, data_test)\n",
        "        # accuracy_test               = compute_accuracy(prediction_test, data_test).to(\"cpu\")\n",
        "        # accuracy_test = accuracy_test.numpy()\n",
        "\n",
        "        loss_test_epoch.append(loss_value_test)\n",
        "        # accuracy_test_epoch.append(accuracy_test)\n",
        "\n",
        "    loss_mean_test[i]      = np.mean(loss_test_epoch)\n",
        "    loss_std_test[i]       = np.std(loss_test_epoch)\n",
        "\n",
        "    # accuracy_mean_test[i]  = np.mean(accuracy_test_epoch)\n",
        "    # accuracy_std_test[i]   = np.std(accuracy_test_epoch)\n",
        "\n",
        "    # print(f\"epoch : {i}, train acc : {np.mean(accuracy_train_epoch)}, train loss : {np.mean(loss_train_epoch)}\")\n",
        "    # print(f\"epoch : {i}, test acc : {np.mean(accuracy_test_epoch)}, test loss : {np.mean(loss_test_epoch)}\")\n",
        "    # print()\n",
        "\n",
        "    print(f\"epoch : {i}, train loss : {np.mean(loss_train_epoch)}\")\n",
        "    print(f\"epoch : {i}, test loss : {np.mean(loss_test_epoch)}\")\n",
        "    print()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "562b4257117145c2a530cac5faaa46f8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0, train loss : 0.29057515656782523\n",
            "epoch : 0, test loss : 0.0905530196097162\n",
            "\n",
            "epoch : 1, train loss : 0.09110138374898169\n",
            "epoch : 1, test loss : 0.08988222595718172\n",
            "\n",
            "epoch : 2, train loss : 0.09182590531806151\n",
            "epoch : 2, test loss : 0.08985763324631585\n",
            "\n",
            "epoch : 3, train loss : 0.09187481266756853\n",
            "epoch : 3, test loss : 0.0899928437338935\n",
            "\n",
            "epoch : 4, train loss : 0.09184577920370632\n",
            "epoch : 4, test loss : 0.09026048514578078\n",
            "\n",
            "epoch : 5, train loss : 0.09186905196143522\n",
            "epoch : 5, test loss : 0.0899471566081047\n",
            "\n",
            "epoch : 6, train loss : 0.09181519088645776\n",
            "epoch : 6, test loss : 0.08985524210664961\n",
            "\n",
            "epoch : 7, train loss : 0.09183365404605866\n",
            "epoch : 7, test loss : 0.08985777944326401\n",
            "\n",
            "epoch : 8, train loss : 0.09190789022379452\n",
            "epoch : 8, test loss : 0.08992664482858446\n",
            "\n",
            "epoch : 9, train loss : 0.09181524788339933\n",
            "epoch : 9, test loss : 0.09015444699260923\n",
            "\n",
            "epoch : 10, train loss : 0.09189969992472066\n",
            "epoch : 10, test loss : 0.08992915136946572\n",
            "\n",
            "epoch : 11, train loss : 0.09182421842383014\n",
            "epoch : 11, test loss : 0.0898553545276324\n",
            "\n",
            "epoch : 12, train loss : 0.09188469577994611\n",
            "epoch : 12, test loss : 0.08989250693056318\n",
            "\n",
            "epoch : 13, train loss : 0.09188790946371025\n",
            "epoch : 13, test loss : 0.08998652729723189\n",
            "\n",
            "epoch : 14, train loss : 0.09192491173744202\n",
            "epoch : 14, test loss : 0.0898680019709799\n",
            "\n",
            "epoch : 15, train loss : 0.09188509260614713\n",
            "epoch : 15, test loss : 0.0899010921518008\n",
            "\n",
            "epoch : 16, train loss : 0.09185455292463303\n",
            "epoch : 16, test loss : 0.08987013068464067\n",
            "\n",
            "epoch : 17, train loss : 0.09185923400024573\n",
            "epoch : 17, test loss : 0.08994066781467862\n",
            "\n",
            "epoch : 18, train loss : 0.0918629922800594\n",
            "epoch : 18, test loss : 0.08987597905927235\n",
            "\n",
            "epoch : 19, train loss : 0.09186058110660977\n",
            "epoch : 19, test loss : 0.08993815647231208\n",
            "\n",
            "epoch : 20, train loss : 0.09181454148557451\n",
            "epoch : 20, test loss : 0.08985237032175064\n",
            "\n",
            "epoch : 21, train loss : 0.09188000518414709\n",
            "epoch : 21, test loss : 0.08999286691347758\n",
            "\n",
            "epoch : 22, train loss : 0.09186017049683465\n",
            "epoch : 22, test loss : 0.08987315694491069\n",
            "\n",
            "epoch : 23, train loss : 0.09193430534667439\n",
            "epoch : 23, test loss : 0.08985482917891609\n",
            "\n",
            "epoch : 24, train loss : 0.09185445561177201\n",
            "epoch : 24, test loss : 0.08986268689235051\n",
            "\n",
            "epoch : 25, train loss : 0.0919064950197935\n",
            "epoch : 25, test loss : 0.09044516334931056\n",
            "\n",
            "epoch : 26, train loss : 0.09185938959320386\n",
            "epoch : 26, test loss : 0.08990255213446087\n",
            "\n",
            "epoch : 27, train loss : 0.09195029023620817\n",
            "epoch : 27, test loss : 0.09017174012131161\n",
            "\n",
            "epoch : 28, train loss : 0.09189088563952182\n",
            "epoch : 28, test loss : 0.08992528021335602\n",
            "\n",
            "epoch : 29, train loss : 0.0918448005285528\n",
            "epoch : 29, test loss : 0.08993298610051473\n",
            "\n",
            "epoch : 30, train loss : 0.0919556234859758\n",
            "epoch : 30, test loss : 0.08986103120777342\n",
            "\n",
            "epoch : 31, train loss : 0.0918483566492796\n",
            "epoch : 31, test loss : 0.08996078537570106\n",
            "\n",
            "epoch : 32, train loss : 0.09186762008402083\n",
            "epoch : 32, test loss : 0.08992266919877794\n",
            "\n",
            "epoch : 33, train loss : 0.09190392142368688\n",
            "epoch : 33, test loss : 0.0898641899228096\n",
            "\n",
            "epoch : 34, train loss : 0.09190120937095748\n",
            "epoch : 34, test loss : 0.09005514515770806\n",
            "\n",
            "epoch : 35, train loss : 0.09192109637790256\n",
            "epoch : 35, test loss : 0.08992268277539148\n",
            "\n",
            "epoch : 36, train loss : 0.09191125341587597\n",
            "epoch : 36, test loss : 0.09003744423389434\n",
            "\n",
            "epoch : 37, train loss : 0.09189565227263503\n",
            "epoch : 37, test loss : 0.08987522042459911\n",
            "\n",
            "epoch : 38, train loss : 0.09191837815774812\n",
            "epoch : 38, test loss : 0.08987941725386514\n",
            "\n",
            "epoch : 39, train loss : 0.09194645293884807\n",
            "epoch : 39, test loss : 0.08988095273574194\n",
            "\n",
            "epoch : 40, train loss : 0.09190890031556288\n",
            "epoch : 40, test loss : 0.08986242810885112\n",
            "\n",
            "epoch : 41, train loss : 0.09189498151342074\n",
            "epoch : 41, test loss : 0.08992305199305216\n",
            "\n",
            "epoch : 42, train loss : 0.09187421955996089\n",
            "epoch : 42, test loss : 0.08985953364107344\n",
            "\n",
            "epoch : 43, train loss : 0.09193635686404175\n",
            "epoch : 43, test loss : 0.08994230975707372\n",
            "\n",
            "epoch : 44, train loss : 0.09193511534896162\n",
            "epoch : 44, test loss : 0.090024443798595\n",
            "\n",
            "epoch : 45, train loss : 0.09190352828138404\n",
            "epoch : 45, test loss : 0.08988741238911947\n",
            "\n",
            "epoch : 46, train loss : 0.09190453232990371\n",
            "epoch : 46, test loss : 0.0898502187596427\n",
            "\n",
            "epoch : 47, train loss : 0.09194667405552334\n",
            "epoch : 47, test loss : 0.08989274352788926\n",
            "\n",
            "epoch : 48, train loss : 0.09195241547293133\n",
            "epoch : 48, test loss : 0.09020228501823213\n",
            "\n",
            "epoch : 49, train loss : 0.09189453414744801\n",
            "epoch : 49, test loss : 0.08989094015624788\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LULSrZv-UTDz"
      },
      "source": [
        "## Plot 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FdiEjDV0kb"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "9ENxj-BQUZ-7",
        "outputId": "a17767a4-d912-4c9f-a0b0-f16d637aa287"
      },
      "source": [
        "print('[plot the training loss]')\n",
        "print('') \n",
        "plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'loss (training)')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[plot the training loss]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bqK2U_jWXva"
      },
      "source": [
        "print('[plot the testing loss]')\n",
        "print('') \n",
        "plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'loss (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J600wqOWgNF"
      },
      "source": [
        "print('[plot the traning accuracy]') \n",
        "print('') \n",
        "plot_curve_error(accuracy_mean_train, accuracy_std_train, 'epoch', 'accuracy', 'Accuracy (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsVmJXxnWIl9"
      },
      "source": [
        "print('[plot the testing accuracy]') \n",
        "print('') \n",
        "plot_curve_error(accuracy_mean_test, accuracy_std_test, 'epoch', 'accuracy', 'Accuracy (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8p8kkmUasj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}