{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "assignment_08_solution_latest_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "84bbda367bac7e7bffd9b7890a44d65326aaedad40e5a9021c2651157391b1ef"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6fc1f5437d7c47ba96565726d79b468a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50513928645d4d239b2b0c504b46b839",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9c9be10bd47946ebbc775b2044c3922d",
              "IPY_MODEL_86cf81c14dac43aaadede9626404fed6",
              "IPY_MODEL_2e32a50f04374423bd7918c044d41ed7"
            ]
          }
        },
        "50513928645d4d239b2b0c504b46b839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c9be10bd47946ebbc775b2044c3922d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45a2d4224ab643b2be8a0f60c0076bf3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "  2%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f15bfe84197940169e19a706ebe81b49"
          }
        },
        "86cf81c14dac43aaadede9626404fed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ec9d2f28720248648026174db7d2862d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 50,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6be51acbf61c481c804dfe6175aa009b"
          }
        },
        "2e32a50f04374423bd7918c044d41ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ff94cd7703449d5aeccb89f0f8ae737",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/50 [00:08&lt;04:25,  5.41s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_397a6a03914e4394a51b71107bd28f66"
          }
        },
        "45a2d4224ab643b2be8a0f60c0076bf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f15bfe84197940169e19a706ebe81b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec9d2f28720248648026174db7d2862d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6be51acbf61c481c804dfe6175aa009b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ff94cd7703449d5aeccb89f0f8ae737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "397a6a03914e4394a51b71107bd28f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tolom131/Human-Activity-Recognition/blob/main/assignment_08_solution_latest_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQGQXmOpA9J-"
      },
      "source": [
        "# Unsupervised image denoising"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGBcGR2LA9KI"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNpI2DZ6A9KJ"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from os import listdir\n",
        "from os.path import join\n",
        "from torchvision.transforms import Compose, ToTensor, ToPILImage, Resize, Lambda, Normalize, Grayscale\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from math import log10\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import math\n",
        "import torch as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20TiZsA_A9KO"
      },
      "source": [
        "## Hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDynD4nA9KP"
      },
      "source": [
        "device        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# ==================================================\n",
        "# determine optimal hyper-parameters to obtain best testing performance\n",
        "number_epoch    = 50\n",
        "size_minibatch  = 64\n",
        "learning_rate   = 0.1\n",
        "# =================================================="
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FriR4w79i_Z",
        "outputId": "769a5639-9a90-4c5d-8ab8-09e724eb6a96"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "directory_data  = './drive/MyDrive/HAR/'\n",
        "filename_data   = 'WISDM_at_v2.0_raw.txt'\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/HAR/')\n",
        "import wisdm_1_1\n",
        "import wisdm_2_0\n",
        "# x_train, y_train, num_classes = wisdm_1_1.create_wisdm_1_1(directory_data + filename_data)\n",
        "origianl_x, original_y, num_classes = wisdm_2_0.create_wisdm_2_0(directory_data + filename_data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape :  (14423, 200, 3) y_train.shape:  (14423, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IsbQDqQ9mCD"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(origianl_x, original_y, random_state=42, stratify=original_y, test_size=0.2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AbHCZPpA9KR"
      },
      "source": [
        "## Costumize dataloader for pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UveCjrBA9KS"
      },
      "source": [
        "class dataset (Dataset):\n",
        "    def  __init__(self, data, label):\n",
        "\n",
        "        self.data    = data\n",
        "        self.label    = label\n",
        "            \n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        data    = self.data[index]\n",
        "        label   = self.label[index]\n",
        "        return (data, label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "357alwWgA9KU"
      },
      "source": [
        "## Construct datasets and dataloaders for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7JDqjSVA9KU"
      },
      "source": [
        "## transformer를 통과하기 위해 데이터 shape 변경\n",
        "x_train = x_train.reshape(-1, x_train.shape[2], x_train.shape[1])\n",
        "x_test = x_test.reshape(-1, x_test.shape[2], x_test.shape[1])\n",
        "\n",
        "dataset_train = dataset(x_train, y_train) \n",
        "dataset_test  = dataset(x_test, y_test) \n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, num_workers=2)\n",
        "dataloader_test  = DataLoader(dataset_test,  batch_size=size_minibatch, shuffle=False, drop_last=True, num_workers=2) "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yn9jMLrA9KX"
      },
      "source": [
        "## Class for the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHuu2uZ9SyRm"
      },
      "source": [
        "class my_MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size=200, num_heads=1):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.multihead = nn.MultiheadAttention(emb_size, num_heads, batch_first=True)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # split keys, queries and values in num_heads\n",
        "        x = self.multihead(inputs, inputs, inputs, need_weights=False)\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TCHYzLmjd3I"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \n",
        "    def __init__(self,max_len,d_model,device):\n",
        "        super(PositionalEncoding,self).__init__()\n",
        "        \n",
        "        self.encoding = torch.zeros(max_len,d_model,device = device)\n",
        "        self.encoding.requires_grad = False # we don't need to compute gradient\n",
        "        \n",
        "        pos = torch.arange(0,max_len,device=device)\n",
        "        pos = pos.float().unsqueeze(dim = 1)\n",
        "        \n",
        "        _2i = torch.arange(0,d_model,step = 2,device = device).float()\n",
        "        \n",
        "        self.encoding[:,0::2] = torch.sin(pos/(10000**(_2i/d_model)))\n",
        "        self.encoding[:,1::2] = torch.cos(pos/(10000**(_2i/d_model)))\n",
        "        \n",
        "    def forward(self,x):\n",
        "        batch_size,seq_len = x.size()\n",
        "        \n",
        "        return self.encoding[:seq_len,:]\n",
        "\n",
        "class ScaleDotProductAttention(nn.Module):\n",
        "    '''\n",
        "    Compute scale dot product attention\n",
        "    실질적인 attention score을 계산하는 클래스\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(ScaleDotProductAttention,self).__init__()\n",
        "        self.softmax = nn.Softmax()\n",
        "        \n",
        "    def forward(self,q,k,v,mask = None, e = 1e-12):\n",
        "        # input is 4 dimension tensor\n",
        "        # [batch_size,head,length,d_tensor]\n",
        "        batch_size,head,length,d_tensor = k.size()\n",
        "        \n",
        "        # 1. dot product Query with Key^T to compute similarity\n",
        "        k_t = k.view(batch_size,head,d_tensor,length)\n",
        "        score = (q @ k_t) / math.sqrt(d_tensor) # @연산은 np.matmul과 같은 역할\n",
        "        \n",
        "        '''\n",
        "        Note) '@' operator\n",
        "        If either argument is N-D, N > 2, \n",
        "        it is treated as a stack of matrices residing in the last two indexes and broadcast accordingly.\n",
        "        '''\n",
        "        \n",
        "        # 2. applying masking(optional)\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask == 0 ,-e)\n",
        "        \n",
        "        # 3. pass tem softmax to make [0,1] range\n",
        "        score = self.softmax(score)\n",
        "        \n",
        "        # 4. Multiply with Value\n",
        "        v = score @ v\n",
        "        \n",
        "        return v, score\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \n",
        "    def __init__(self,d_model,n_head):\n",
        "        super(MultiHeadAttention,self).__init__()\n",
        "        self.n_head = n_head\n",
        "        self.attention = ScaleDotProductAttention()\n",
        "        self.w_q = nn.Linear(d_model,d_model)\n",
        "        self.w_k = nn.Linear(d_model,d_model)\n",
        "        self.w_v = nn.Linear(d_model,d_model)\n",
        "        self.w_concat = nn.Linear(d_model,d_model)\n",
        "    \n",
        "    def split(self,tensor):\n",
        "        '''\n",
        "        splits tensor by number of head\n",
        "        \n",
        "        param tensor = [batch_size,length,d_model]\n",
        "        out = [batch_size,head,length,d_tensor]\n",
        "        \n",
        "        d_model을 head와 d_tensor로 쪼개는걸로 이해하면 될듯. \n",
        "        d_tensor는 head의 값에 따라 변함.(head값은 정해주는 값이기 때문..)\n",
        "        '''\n",
        "        batch_size,length,d_model = tensor.size()\n",
        "        \n",
        "        d_tensor = d_model//self.n_head\n",
        "        \n",
        "        tensor = tensor.view(batch_size,self.n_head,length,d_tensor)\n",
        "        \n",
        "        return tensor\n",
        "    \n",
        "    def concat(self,tensor):\n",
        "        '''\n",
        "        inverse function of self.split(tensor = torch.Tensor)\n",
        "        \n",
        "        param tensor = [batch_size,head,length,d_tensor]\n",
        "        out = [batch_size,length,d_model]\n",
        "        '''\n",
        "        batch_size,head,length,d_tensor = tensor.size()\n",
        "        d_model = head*d_tensor\n",
        "        \n",
        "        tensor = tensor.view(batch_size,length,d_model)\n",
        "        return tensor\n",
        "    \n",
        "    def forward(self,q,k,v,mask = None):\n",
        "        \n",
        "        #1. dot product with weight metrics\n",
        "        q,k,v = self.w_q(q),self.w_k(k),self.w_v(v)\n",
        "        \n",
        "        # 2. split tensor by number of heads\n",
        "        q,k,v = self.split(q),self.split(k),self.split(v)\n",
        "        \n",
        "        # 3. do scale dot product to compute similarity (attention 계산)\n",
        "        out,attention = self.attention(q,k,v, mask = mask)\n",
        "        \n",
        "        # 4. concat and pass to linear layer\n",
        "        out = self.concat(out)\n",
        "        out = self.w_concat(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75QGenrzTEAR"
      },
      "source": [
        "# 수정: 오토 인코더의 인코더처럼 만들기 위해 마지막 Linear에서 그 크기를 줄여준다.\n",
        "class FeedForwardBlock_Encoder(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, reduction=1):\n",
        "        super(FeedForwardBlock_Encoder, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channel, in_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.batch1 = nn.BatchNorm1d(in_channel)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channel, out_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.batch2 = nn.BatchNorm1d(out_channel)            \n",
        "\n",
        "        self.pool = nn.MaxPool1d(2, 2)\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.relu1(x)\n",
        "        x = self.batch1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.batch2(x)\n",
        "\n",
        "        if self.reduction == 2:\n",
        "            x = self.pool(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2fieNGYV4xe"
      },
      "source": [
        "# Now create the Transformer Encoder Block\n",
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, dim=768, in_channel=16, out_channel=16, reduction=1, **kwargs):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "\n",
        "        self.laynorm1 = nn.LayerNorm(dim)\n",
        "        self.multihead1 = MultiHeadAttention(dim, 1)\n",
        "\n",
        "        self.laynorm2 = nn.LayerNorm(dim)\n",
        "        self.ff = FeedForwardBlock_Encoder(in_channel, out_channel, reduction=reduction)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        _x = inputs\n",
        "        x = self.laynorm1(inputs)\n",
        "        x = self.multihead1(x, x, x)\n",
        "        x += _x\n",
        "\n",
        "        x = self.laynorm2(x)\n",
        "        x = self.ff(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26QaLC6AWsO9"
      },
      "source": [
        "# 수정: 오토 인코더의 인코더처럼 만들기 위해 마지막 Linear에서 그 크기를 줄여준다.\n",
        "class FeedForwardBlock_Decoder(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, amp=1):\n",
        "        super(FeedForwardBlock_Decoder, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channel, in_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.batch1 = nn.BatchNorm1d(in_channel)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channel, out_channel, kernel_size=3, padding=1, stride=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.batch2 = nn.BatchNorm1d(out_channel)            \n",
        "\n",
        "        self.pool = nn.Upsample(scale_factor=2, mode=\"nearest\")\n",
        "        self.amp = amp\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.relu1(x)\n",
        "        x = self.batch1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.batch2(x)\n",
        "\n",
        "        if self.amp == 2:\n",
        "            x = self.pool(x)\n",
        "        return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ys44YMV2bL"
      },
      "source": [
        "# Now create the Transformer Encoder Block\n",
        "class TransformerDecoderBlock(nn.Module):\n",
        "    def __init__(self, dim=768, in_channel=16, out_channel=16, amp=1, **kwargs):\n",
        "        super(TransformerDecoderBlock, self).__init__()\n",
        "\n",
        "        self.laynorm1 = nn.LayerNorm(dim)\n",
        "        self.multihead1 = MultiHeadAttention(dim, 1)\n",
        "\n",
        "        self.laynorm2 = nn.LayerNorm(dim)\n",
        "        self.ff =  FeedForwardBlock_Decoder(in_channel, out_channel, amp)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        _x = inputs\n",
        "        x = self.laynorm1(inputs)\n",
        "        x = self.multihead1(x, x, x)\n",
        "        x += _x\n",
        "\n",
        "        x = self.laynorm2(x)\n",
        "        x = self.ff(x)\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VPt0SXOTuS3"
      },
      "source": [
        "class Conseuctive_Conv(nn.Sequential):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__(\n",
        "            nn.Conv1d(dim, dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(dim, dim, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(dim, dim, kernel_size=3, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, dim, channel):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.channel = channel\n",
        "\n",
        "        self.conv1 = Conseuctive_Conv(channel*20)\n",
        "        self.conv2 = Conseuctive_Conv(channel*40)\n",
        "\n",
        "        self.encoder12 = TransformerEncoderBlock(dim=dim,     in_channel=channel,    out_channel=channel*20,  reduction=2)\n",
        "        self.encoder22 = TransformerEncoderBlock(dim=dim//2,  in_channel=channel*20, out_channel=channel*40,  reduction=2)\n",
        "        self.encoder32 = TransformerEncoderBlock(dim=dim//4,  in_channel=channel*40, out_channel=channel*80,  reduction=2)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.encoder12(inputs)    \n",
        "        x = self.conv1(x)\n",
        "        x = self.encoder22(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.encoder32(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, dim, channel):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.channel = channel\n",
        "\n",
        "        self.conv3 = Conseuctive_Conv(channel*40)\n",
        "        self.conv4 = Conseuctive_Conv(channel*20)\n",
        "\n",
        "        self.decoder12 = TransformerDecoderBlock(dim=dim//8,  in_channel=channel*80, out_channel=channel*40, amp=2)\n",
        "        self.decoder22 = TransformerDecoderBlock(dim=dim//4,  in_channel=channel*40, out_channel=channel*20, amp=2)\n",
        "        self.decoder32 = TransformerDecoderBlock(dim=dim//2,  in_channel=channel*20, out_channel=channel,    amp=2)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.decoder12(inputs)\n",
        "        x = self.conv3(x)\n",
        "        x = self.decoder22(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.decoder32(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, dim, channel, num_classes, is_alone=False):\n",
        "        super(Classifier, self).__init__()\n",
        "        \n",
        "        if is_alone:\n",
        "            self.dim = dim\n",
        "            self.channel = channel\n",
        "            self.num_classes = num_classes\n",
        "        else:\n",
        "            self.dim = dim//8\n",
        "            self.channel = channel*80\n",
        "            self.num_classes = num_classes\n",
        "\n",
        "        # original inputs shape : [batch_size, channel, dim]\n",
        "        # classifier inputs shape : [batch_size, channel*80, dim//8]\n",
        "\n",
        "        self.conv1 = nn.Conv1d(self.channel, 64, kernel_size=3, padding=1, stride=1)\n",
        "        self.batch1 = nn.BatchNorm1d(64)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1, stride=1)\n",
        "        self.batch2 = nn.BatchNorm1d(128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        \n",
        "        self.lstm = nn.LSTM(self.dim, self.dim, batch_first=True)\n",
        "        self.classifier = nn.Linear(self.dim, self.num_classes)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.batch1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.batch2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]         # return_sequences = False\n",
        "        x = self.classifier(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x  \n",
        "\n",
        "class SupervisedAutoencoder(nn.Module):\n",
        "    def __init__(self, dim, channel, num_classes):\n",
        "        super(SupervisedAutoencoder, self).__init__()\n",
        "\n",
        "        self.dim = dim\n",
        "        self.channel = channel\n",
        "\n",
        "        self.encoder = Encoder(dim, channel)\n",
        "        self.decoder = Decoder(dim, channel)\n",
        "\n",
        "        self.classifier = Classifier(dim, channel, num_classes) \n",
        "\n",
        "    def forward(self, inputs):\n",
        "\n",
        "        x = self.encoder(inputs)\n",
        "        classified = self.classifier(x)\n",
        "        decoded = self.decoder(x)\n",
        "        return classified, decoded"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uig2PSDaTDu6"
      },
      "source": [
        "## model summary 용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmCOhVRTAUly"
      },
      "source": [
        "# from torchsummary import summary as summary_\n",
        "\n",
        "# model = Transformer_Autoencoder().to(device)\n",
        "# summary_(model, (3, 200))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8DSwKtMOqBH"
      },
      "source": [
        "## 모델링 과정을 위해 필요한 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCOI_G1tnmUE"
      },
      "source": [
        "def compute_prediction(model, input):\n",
        "    prediction, decoded = model(input)\n",
        "    return prediction, decoded"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yA0KNRpEnnN6"
      },
      "source": [
        "def compute_mse_loss(input, prediction):\n",
        "    \n",
        "    mse = nn.MSELoss()\n",
        "    \n",
        "    # ==================================================\n",
        "    # fill up the blank\n",
        "    loss_mse = mse(prediction, input)\n",
        "    # ==================================================\n",
        "    \n",
        "    loss_mse_value = loss_mse.item() \n",
        "    \n",
        "    return loss_mse, loss_mse_value"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT9FgvXjcVBB"
      },
      "source": [
        "def compute_entropy_loss(inputs, prediction):\n",
        "    cross = nn.CrossEntropyLoss()\n",
        "\n",
        "    loss_cross = cross(prediction, inputs)\n",
        "\n",
        "    loss_cross_value = loss_cross.item()\n",
        "    return loss_cross, loss_cross_value"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlSY2TrROn6W"
      },
      "source": [
        "def compute_accuracy(prediction, label):\n",
        "    # ================================================================================ \n",
        "    # complete the function body\n",
        "    b_Prediction = torch.argmax(prediction, 1)\n",
        "    b_label = torch.argmax(label, 1)\n",
        "    bCorrect = (b_Prediction == b_label)\n",
        "    accuracy = bCorrect.float().mean() * 100\n",
        "    # ================================================================================ \n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DYCbEtyPHW5"
      },
      "source": [
        "## 모델링 과정 정리를 위한 배열"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2GV2m67PGMD"
      },
      "source": [
        "loss_mean_train     = np.zeros(number_epoch)\n",
        "loss_std_train      = np.zeros(number_epoch)\n",
        "accuracy_mean_train = np.zeros(number_epoch)\n",
        "accuracy_std_train  = np.zeros(number_epoch)\n",
        "\n",
        "loss_mean_test      = np.zeros(number_epoch)\n",
        "loss_std_test       = np.zeros(number_epoch)\n",
        "accuracy_mean_test  = np.zeros(number_epoch)\n",
        "accuracy_std_test   = np.zeros(number_epoch)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTptbDGZA9KZ"
      },
      "source": [
        "## Build the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MgUbMJdA9KZ"
      },
      "source": [
        "# model = Classifier(200, 3, 6, is_alone=True).to(device)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzsj97WB3_tq"
      },
      "source": [
        "model = SupervisedAutoencoder(200, 3, 6).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NKn_pSx3L0H"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492,
          "referenced_widgets": [
            "6fc1f5437d7c47ba96565726d79b468a",
            "50513928645d4d239b2b0c504b46b839",
            "9c9be10bd47946ebbc775b2044c3922d",
            "86cf81c14dac43aaadede9626404fed6",
            "2e32a50f04374423bd7918c044d41ed7",
            "45a2d4224ab643b2be8a0f60c0076bf3",
            "f15bfe84197940169e19a706ebe81b49",
            "ec9d2f28720248648026174db7d2862d",
            "6be51acbf61c481c804dfe6175aa009b",
            "4ff94cd7703449d5aeccb89f0f8ae737",
            "397a6a03914e4394a51b71107bd28f66"
          ]
        },
        "id": "UYEYvwqKmz-V",
        "outputId": "4187492c-8f0c-4aef-d070-e7adf1f109be"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_train_epoch        = []\n",
        "    accuracy_train_epoch    = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_train):\n",
        "\n",
        "        data_train = data.to(device)\n",
        "        label_train = label.to(device)\n",
        "        \n",
        "        classified, decoded = compute_prediction(model, data_train)\n",
        "\n",
        "        # classified loss\n",
        "        classified_loss, classfied_loss_value       = compute_entropy_loss(label_train, classified)\n",
        "\n",
        "        # decoded loss\n",
        "        decoded_loss, decoded_loss_value            = compute_mse_loss(data_train, decoded)\n",
        "\n",
        "        # classified accuracy\n",
        "        accuracy_train                              = compute_accuracy(classified, label_train).to(\"cpu\")\n",
        "        accuracy_train = accuracy_train.numpy()\n",
        "\n",
        "        loss_train = classified_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_train_epoch.append(classfied_loss_value)\n",
        "        accuracy_train_epoch.append(accuracy_train)\n",
        "\n",
        "    loss_mean_train[i]      = np.mean(loss_train_epoch)\n",
        "    loss_std_train[i]       = np.std(loss_train_epoch)\n",
        "\n",
        "    accuracy_mean_train[i]  = np.mean(accuracy_train_epoch)\n",
        "    accuracy_std_train[i]   = np.std(accuracy_train_epoch)\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_test_epoch        = []\n",
        "    accuracy_test_epoch    = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_test):\n",
        "\n",
        "        data_test = data.to(device)\n",
        "        label_test = label.to(device)\n",
        "        \n",
        "        classified, decoded             = compute_prediction(model, data_test)\n",
        "\n",
        "        # classified loss\n",
        "        classified_loss, classfied_loss_value       = compute_entropy_loss(label_test, classified)\n",
        "\n",
        "        # decoded loss\n",
        "        decoded_loss, decoded_loss_value            = compute_mse_loss(data_test, decoded)\n",
        "\n",
        "        # classified accuracy\n",
        "        accuracy_test               = compute_accuracy(classified, label_test).to(\"cpu\")\n",
        "        accuracy_test = accuracy_test.numpy()\n",
        "\n",
        "        loss_test_epoch.append(classfied_loss_value)\n",
        "        accuracy_test_epoch.append(accuracy_test)\n",
        "\n",
        "    loss_mean_test[i]      = np.mean(loss_test_epoch)\n",
        "    loss_std_test[i]       = np.std(loss_test_epoch)\n",
        "\n",
        "    accuracy_mean_test[i]  = np.mean(accuracy_test_epoch)\n",
        "    accuracy_std_test[i]   = np.std(accuracy_test_epoch)\n",
        "\n",
        "    print(f\"epoch : {i}, train acc : {np.mean(accuracy_train_epoch)}, train loss : {np.mean(loss_train_epoch)}\")\n",
        "    print(f\"epoch : {i}, test acc : {np.mean(accuracy_test_epoch)}, test loss : {np.mean(loss_test_epoch)}\")\n",
        "    print()\n",
        "\n",
        "    # print(f\"epoch : {i}, train loss : {np.mean(loss_train_epoch)}\")\n",
        "    # print(f\"epoch : {i}, test loss : {np.mean(loss_test_epoch)}\")\n",
        "    # print()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6fc1f5437d7c47ba96565726d79b468a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch : 0, train acc : 42.23958206176758, train loss : 1.6189056787225935\n",
            "epoch : 0, test acc : 42.5, test loss : 1.613098555141025\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4248afec6ae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mloss_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOG-mR8F3Tzq"
      },
      "source": [
        "## Classifier 독립"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GDDgXPRy3Wir"
      },
      "source": [
        "# ================================================================================\n",
        "# \n",
        "# iterations for epochs\n",
        "#\n",
        "# ================================================================================\n",
        "for i in tqdm(range(number_epoch)):\n",
        "    \n",
        "    # ================================================================================\n",
        "    # \n",
        "    # training\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_train_epoch        = []\n",
        "    accuracy_train_epoch    = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_train):\n",
        "\n",
        "        data_train = data.to(device)\n",
        "        label_train = label.to(device)\n",
        "        \n",
        "        classified = compute_prediction(model, data_train)\n",
        "\n",
        "        # classified loss\n",
        "        classified_loss, classfied_loss_value       = compute_entropy_loss(label_train, classified)\n",
        "\n",
        "        # classified accuracy\n",
        "        accuracy_train                              = compute_accuracy(classified, label_train).to(\"cpu\")\n",
        "        accuracy_train = accuracy_train.numpy()\n",
        "\n",
        "        loss_train = classified_loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss_train.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_train_epoch.append(classfied_loss_value)\n",
        "        accuracy_train_epoch.append(accuracy_train)\n",
        "\n",
        "    loss_mean_train[i]      = np.mean(loss_train_epoch)\n",
        "    loss_std_train[i]       = np.std(loss_train_epoch)\n",
        "\n",
        "    accuracy_mean_train[i]  = np.mean(accuracy_train_epoch)\n",
        "    accuracy_std_train[i]   = np.std(accuracy_train_epoch)\n",
        "\n",
        "    # ================================================================================\n",
        "    # \n",
        "    # testing\n",
        "    #\n",
        "    # ================================================================================\n",
        "    loss_test_epoch        = []\n",
        "    accuracy_test_epoch    = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "\n",
        "    for index_batch, (data, label) in enumerate(dataloader_test):\n",
        "\n",
        "        data_test = data.to(device)\n",
        "        label_test = label.to(device)\n",
        "        \n",
        "        classified             = compute_prediction(model, data_test)\n",
        "\n",
        "        # classified loss\n",
        "        classified_loss, classfied_loss_value       = compute_entropy_loss(label_test, classified)\n",
        "\n",
        "        # classified accuracy\n",
        "        accuracy_test               = compute_accuracy(classified, label_test).to(\"cpu\")\n",
        "        accuracy_test = accuracy_test.numpy()\n",
        "\n",
        "        loss_test_epoch.append(classfied_loss_value)\n",
        "        accuracy_test_epoch.append(accuracy_test)\n",
        "\n",
        "    loss_mean_test[i]      = np.mean(loss_test_epoch)\n",
        "    loss_std_test[i]       = np.std(loss_test_epoch)\n",
        "\n",
        "    accuracy_mean_test[i]  = np.mean(accuracy_test_epoch)\n",
        "    accuracy_std_test[i]   = np.std(accuracy_test_epoch)\n",
        "\n",
        "    print(f\"epoch : {i}, train acc : {np.mean(accuracy_train_epoch)}, train loss : {np.mean(loss_train_epoch)}\")\n",
        "    print(f\"epoch : {i}, test acc : {np.mean(accuracy_test_epoch)}, test loss : {np.mean(loss_test_epoch)}\")\n",
        "    print()\n",
        "\n",
        "    # print(f\"epoch : {i}, train loss : {np.mean(loss_train_epoch)}\")\n",
        "    # print(f\"epoch : {i}, test loss : {np.mean(loss_test_epoch)}\")\n",
        "    # print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LULSrZv-UTDz"
      },
      "source": [
        "## Plot 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08FdiEjDV0kb"
      },
      "source": [
        "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.title(title)\n",
        "\n",
        "    alpha = 0.3\n",
        "    \n",
        "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
        "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
        "    \n",
        "    plt.xlabel(x_label)\n",
        "    plt.ylabel(y_label)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ENxj-BQUZ-7"
      },
      "source": [
        "print('[plot the training loss]')\n",
        "print('') \n",
        "plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'loss (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bqK2U_jWXva"
      },
      "source": [
        "print('[plot the testing loss]')\n",
        "print('') \n",
        "plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'loss (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J600wqOWgNF"
      },
      "source": [
        "print('[plot the traning accuracy]') \n",
        "print('') \n",
        "plot_curve_error(accuracy_mean_train, accuracy_std_train, 'epoch', 'accuracy', 'Accuracy (training)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsVmJXxnWIl9"
      },
      "source": [
        "print('[plot the testing accuracy]') \n",
        "print('') \n",
        "plot_curve_error(accuracy_mean_test, accuracy_std_test, 'epoch', 'accuracy', 'Accuracy (testing)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aF8p8kkmUasj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
